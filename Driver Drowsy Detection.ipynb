{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8373,"status":"ok","timestamp":1737863399748,"user":{"displayName":"Kevin Harry","userId":"14407016036151746140"},"user_tz":-330},"id":"2DcK6VNptekZ","outputId":"bbe503e0-fff0-4052-dac5-2f648f7fc7d1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.17.1)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.1.21)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.5)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.69.0)\n","Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.17.1)\n","Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.5.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (0.14.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"]}],"source":["!pip install tensorflow"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6333,"status":"ok","timestamp":1737863411116,"user":{"displayName":"Kevin Harry","userId":"14407016036151746140"},"user_tz":-330},"id":"s-gAzCx-uObf","outputId":"39d68e73-7187-4cb4-b058-3d8ca1ab1c40"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.17.1)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.1.21)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.5)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.69.0)\n","Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.17.1)\n","Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.5.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (0.14.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"]}],"source":["pip install tensorflow pillow\n"]},{"cell_type":"markdown","metadata":{"id":"D4eP6JYrydvM"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":107},"executionInfo":{"elapsed":186030,"status":"ok","timestamp":1737863606904,"user":{"displayName":"Kevin Harry","userId":"14407016036151746140"},"user_tz":-330},"id":"nFHouZHEJ_aU","outputId":"239690f2-569d-48cc-afcc-e4fbaea37366"},"outputs":[{"data":{"text/html":["\n","     <input type=\"file\" id=\"files-f0143787-f550-4556-ae7e-ac884b94be37\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-f0143787-f550-4556-ae7e-ac884b94be37\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Saving converted_keras.zip to converted_keras.zip\n","Saving converted_savedmodel.zip to converted_savedmodel.zip\n"]}],"source":["import zipfile\n","from google.colab import files\n","\n","# Upload zipped folders\n","uploaded = files.upload()\n","\n","# Extract the Drowsy and Non Drowsy folders\n","for filename in uploaded.keys():\n","    with zipfile.ZipFile(filename, 'r') as zip_ref:\n","        zip_ref.extractall()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"executionInfo":{"elapsed":615,"status":"error","timestamp":1737789062835,"user":{"displayName":"Kevin Harry","userId":"14407016036151746140"},"user_tz":-330},"id":"tMZyFbpNK09j","outputId":"c1f98134-24f9-4e70-e9f2-f39823a04f59"},"outputs":[{"ename":"TypeError","evalue":"Error when deserializing class 'DepthwiseConv2D' using config={'name': 'expanded_conv_depthwise', 'trainable': True, 'dtype': 'float32', 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'linear', 'use_bias': False, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_regularizer': None, 'activity_regularizer': None, 'bias_constraint': None, 'depth_multiplier': 1, 'depthwise_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'depthwise_regularizer': None, 'depthwise_constraint': None}.\n\nException encountered: Unrecognized keyword arguments passed to DepthwiseConv2D: {'groups': 1}","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/ops/operation.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/depthwise_conv2d.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, kernel_size, strides, padding, depth_multiplier, data_format, dilation_rate, activation, use_bias, depthwise_initializer, bias_initializer, depthwise_regularizer, bias_regularizer, activity_regularizer, depthwise_constraint, bias_constraint, **kwargs)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_depthwise_conv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, rank, depth_multiplier, kernel_size, strides, padding, data_format, dilation_rate, activation, use_bias, depthwise_initializer, bias_initializer, depthwise_regularizer, bias_regularizer, activity_regularizer, depthwise_constraint, bias_constraint, trainable, name, **kwargs)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, activity_regularizer, trainable, dtype, autocast, name, **kwargs)\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Unrecognized keyword arguments passed to DepthwiseConv2D: {'groups': 1}","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-317728f6442f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Load the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/keras_model.h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Load the labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/legacy_h5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/saving_utils.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/serialization.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/sequential.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/saving_utils.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/serialization.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/sequential.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/saving_utils.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/serialization.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/model.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py\u001b[0m in \u001b[0;36mfunctional_from_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py\u001b[0m in \u001b[0;36mprocess_layer\u001b[0;34m(layer_data)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/saving_utils.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/serialization.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/ops/operation.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config)\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Error when deserializing class 'DepthwiseConv2D' using config={'name': 'expanded_conv_depthwise', 'trainable': True, 'dtype': 'float32', 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'linear', 'use_bias': False, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_regularizer': None, 'activity_regularizer': None, 'bias_constraint': None, 'depth_multiplier': 1, 'depthwise_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'depthwise_regularizer': None, 'depthwise_constraint': None}.\n\nException encountered: Unrecognized keyword arguments passed to DepthwiseConv2D: {'groups': 1}"]}],"source":["import cv2\n","import numpy as np\n","from keras.models import load_model\n","from PIL import Image, ImageOps\n","\n","# Load the model\n","model = load_model(\"/content/keras_model.h5\", compile=False)\n","\n","# Load the labels\n","class_names = open(\"/content/labels.txt\", \"r\").readlines()\n","\n","# Initialize the webcam\n","camera = cv2.VideoCapture(0)\n","\n","while True:\n","    # Capture frame-by-frame\n","    ret, frame = camera.read()\n","    if not ret:\n","        break\n","\n","    # Convert the frame to RGB\n","    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","\n","    # Resize the image to 224x224 pixels\n","    image = Image.fromarray(image)\n","    image = ImageOps.fit(image, (224, 224), Image.Resampling.LANCZOS)\n","    image_array = np.asarray(image)\n","\n","    # Normalize the image\n","    normalized_image_array = (image_array.astype(np.float32) / 127.5) - 1\n","\n","    # Create a batch of one image\n","    data = np.expand_dims(normalized_image_array, axis=0)\n","\n","    # Perform prediction\n","    prediction = model.predict(data)\n","    index = np.argmax(prediction)\n","    class_name = class_names[index].strip()\n","    confidence_score = prediction[0][index]\n","\n","    # Display the resulting frame\n","    cv2.putText(frame, f\"{class_name}: {confidence_score:.2f}\", (10, 30),\n","                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n","    cv2.imshow('Drowsiness Detection', frame)\n","\n","    # Break the loop on 'q' key press\n","    if cv2.waitKey(1) & 0xFF == ord('q'):\n","        break\n","\n","# Release the webcam and close windows\n","camera.release()\n","cv2.destroyAllWindows()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":73},"executionInfo":{"elapsed":26931,"status":"ok","timestamp":1737863895470,"user":{"displayName":"Kevin Harry","userId":"14407016036151746140"},"user_tz":-330},"id":"NobNcKWnGRuk","outputId":"e292b6b7-fd9e-4f5f-d27d-4641dc2bed1a"},"outputs":[{"data":{"text/html":["\n","     <input type=\"file\" id=\"files-569a93e6-3706-467e-96ef-f05b43fbd26d\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-569a93e6-3706-467e-96ef-f05b43fbd26d\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Saving alert.wav to alert.wav\n"]}],"source":["from google.colab import files\n","\n","# Upload the alert sound file\n","uploaded = files.upload()\n","\n","# Get the file name\n","alert_sound_file = list(uploaded.keys())[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":173},"executionInfo":{"elapsed":11277,"status":"ok","timestamp":1737865109041,"user":{"displayName":"Kevin Harry","userId":"14407016036151746140"},"user_tz":-330},"id":"cZzW8TIfXDRj","outputId":"19582b89-1bf1-4988-b28a-8d466018c818"},"outputs":[{"data":{"application/javascript":["\n","        async function takePhoto() {\n","            const div = document.createElement('div');\n","            const video = document.createElement('video');\n","            const canvas = document.createElement('canvas');\n","            const button = document.createElement('button');\n","            button.textContent = 'Stop';\n","\n","            div.appendChild(video);\n","            div.appendChild(button);\n","            document.body.appendChild(div);\n","\n","            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n","            video.srcObject = stream;\n","            await video.play();\n","\n","            async function captureFrame() {\n","                if (!video.srcObject.active) {\n","                    return null;\n","                }\n","                canvas.width = video.videoWidth;\n","                canvas.height = video.videoHeight;\n","                canvas.getContext('2d').drawImage(video, 0, 0);\n","                return canvas.toDataURL('image/jpeg').split(',')[1];\n","            }\n","\n","            button.onclick = () => {\n","                stream.getTracks().forEach(track => track.stop());\n","                div.remove();\n","            };\n","\n","            while (video.srcObject.active) {\n","                const image = await captureFrame();\n","                google.colab.kernel.invokeFunction('notebook.captureFrameCallback', [image], {});\n","                await new Promise(resolve => setTimeout(resolve, 1000)); // Capture every second\n","            }\n","        }\n","        takePhoto();\n","    "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"}],"source":["import cv2\n","import numpy as np\n","from keras.models import load_model\n","from PIL import Image, ImageOps\n","from google.colab.patches import cv2_imshow\n","from google.colab import output\n","import base64\n","import io\n","from IPython.display import display, Javascript, Audio\n","\n","# Load the model\n","model = load_model(\"/content/keras_model.h5\", compile=False)\n","\n","# Load the labels\n","class_names = open(\"/content/labels.txt\", \"r\").readlines()\n","\n","# Global variables\n","drowsy_frame_count = 0\n","ALERT_THRESHOLD = 5  # Number of continuous drowsy frames to trigger alert\n","alert_sound_file = \"/content/alert.wav\"  # Path to the alert sound file\n","\n","def capture_image():\n","    \"\"\"\n","    Function to capture an image from the webcam via JavaScript.\n","    \"\"\"\n","    js = Javascript('''\n","        async function takePhoto() {\n","            const div = document.createElement('div');\n","            const video = document.createElement('video');\n","            const canvas = document.createElement('canvas');\n","            const button = document.createElement('button');\n","            button.textContent = 'Stop';\n","\n","            div.appendChild(video);\n","            div.appendChild(button);\n","            document.body.appendChild(div);\n","\n","            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n","            video.srcObject = stream;\n","            await video.play();\n","\n","            async function captureFrame() {\n","                if (!video.srcObject.active) {\n","                    return null;\n","                }\n","                canvas.width = video.videoWidth;\n","                canvas.height = video.videoHeight;\n","                canvas.getContext('2d').drawImage(video, 0, 0);\n","                return canvas.toDataURL('image/jpeg').split(',')[1];\n","            }\n","\n","            button.onclick = () => {\n","                stream.getTracks().forEach(track => track.stop());\n","                div.remove();\n","            };\n","\n","            while (video.srcObject.active) {\n","                const image = await captureFrame();\n","                google.colab.kernel.invokeFunction('notebook.captureFrameCallback', [image], {});\n","                await new Promise(resolve => setTimeout(resolve, 1000)); // Capture every second\n","            }\n","        }\n","        takePhoto();\n","    ''')\n","    display(js)\n","\n","def process_frame(frame):\n","    \"\"\"\n","    Process the frame and make a prediction.\n","    \"\"\"\n","    global drowsy_frame_count\n","\n","    # Resize the frame to 224x224 pixels\n","    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","    image = Image.fromarray(image)\n","    image = ImageOps.fit(image, (224, 224), Image.Resampling.LANCZOS)\n","    image_array = np.asarray(image)\n","\n","    # Normalize the image\n","    normalized_image_array = (image_array.astype(np.float32) / 127.5) - 1\n","\n","    # Create a batch of one image\n","    data = np.expand_dims(normalized_image_array, axis=0)\n","\n","    # Perform prediction\n","    prediction = model.predict(data)\n","    index = np.argmax(prediction)\n","    class_name = class_names[index].strip()\n","    confidence_score = prediction[0][index]\n","\n","    # Check if the class is \"drowsy\"\n","    if class_name == \"drowsy\":\n","        drowsy_frame_count += 1\n","    else:\n","        drowsy_frame_count = 0  # Reset the counter if not drowsy\n","\n","    # Trigger alert if continuous drowsy frames exceed the threshold\n","    if drowsy_frame_count >= ALERT_THRESHOLD:\n","        display(Audio(alert_sound_file, autoplay=True))\n","        drowsy_frame_count = 0  # Reset the counter after alert\n","\n","    return class_name, confidence_score\n","\n","def capture_frame_callback(image_data):\n","    \"\"\"\n","    Callback to process the captured image.\n","    \"\"\"\n","    global drowsy_frame_count\n","\n","    if image_data is None:\n","        return\n","\n","    # Decode the image data\n","    image_bytes = base64.b64decode(image_data)\n","    frame = Image.open(io.BytesIO(image_bytes))\n","    frame = cv2.cvtColor(np.array(frame), cv2.COLOR_RGB2BGR)\n","\n","    # Process the frame\n","    class_name, confidence_score = process_frame(frame)\n","\n","    # Display the result\n","    cv2.putText(frame, f\"{class_name}: {confidence_score:.2f}\", (10, 30),\n","                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n","    cv2_imshow(frame)\n","\n","# Register callback function\n","output.register_callback('notebook.captureFrameCallback', capture_frame_callback)\n","\n","# Start capturing\n","capture_image()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3972,"status":"ok","timestamp":1737864758163,"user":{"displayName":"Kevin Harry","userId":"14407016036151746140"},"user_tz":-330},"id":"6yhv3I_MQAdZ","outputId":"c75e4c65-bd36-41fd-9172-e1c904c88935"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.10.0.84)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (1.26.4)\n"]}],"source":["!pip install opencv-python\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3022,"status":"ok","timestamp":1737864929028,"user":{"displayName":"Kevin Harry","userId":"14407016036151746140"},"user_tz":-330},"id":"QHiZyl4fLz5P","outputId":"087b7f08-3f9d-42a5-f3c1-98d4bd295d87"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tensorflow==2.12 in /usr/local/lib/python3.11/dist-packages (2.12.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (1.6.3)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (25.1.21)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (1.69.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (3.12.1)\n","Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (0.4.30)\n","Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (2.12.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (18.1.1)\n","Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (1.23.5)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (24.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (4.25.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (75.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (1.17.0)\n","Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (2.12.3)\n","Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (2.12.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (2.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (4.12.2)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (0.37.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.12) (0.45.1)\n","Requirement already satisfied: jaxlib<=0.4.30,>=0.4.27 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12) (0.4.30)\n","Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12) (0.4.1)\n","Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12) (1.13.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (3.7)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (2.32.3)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (3.1.3)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (5.5.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (0.4.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (2024.12.14)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.0.2)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (0.6.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.2.2)\n"]}],"source":["pip install tensorflow==2.12\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3751,"status":"ok","timestamp":1737864954122,"user":{"displayName":"Kevin Harry","userId":"14407016036151746140"},"user_tz":-330},"id":"GPieMSrYROVT","outputId":"9adc4935-050f-44d8-b2a2-1b256760067a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n","0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"]}],"source":["!apt install ffmpeg"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1909,"status":"ok","timestamp":1737864964704,"user":{"displayName":"Kevin Harry","userId":"14407016036151746140"},"user_tz":-330},"id":"0jCiSyQ0RT3g","outputId":"6934acfd-8a96-4464-8e02-937195320d27"},"outputs":[{"name":"stdout","output_type":"stream","text":["ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n","  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n","  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n","  libavutil      56. 70.100 / 56. 70.100\n","  libavcodec     58.134.100 / 58.134.100\n","  libavformat    58. 76.100 / 58. 76.100\n","  libavdevice    58. 13.100 / 58. 13.100\n","  libavfilter     7.110.100 /  7.110.100\n","  libswscale      5.  9.100 /  5.  9.100\n","  libswresample   3.  9.100 /  3.  9.100\n","  libpostproc    55.  9.100 / 55.  9.100\n","\u001b[0;33mGuessed Channel Layout for Input Stream #0.0 : stereo\n","\u001b[0mInput #0, wav, from '/content/alert.wav':\n","  Metadata:\n","    encoder         : Lavf61.1.100\n","  Duration: 00:00:04.02, bitrate: 1411 kb/s\n","  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s\n","Stream mapping:\n","  Stream #0:0 -> #0:0 (pcm_s16le (native) -> mp3 (libmp3lame))\n","Press [q] to stop, [?] for help\n","Output #0, mp3, to '/content/alert.mp3':\n","  Metadata:\n","    TSSE            : Lavf58.76.100\n","  Stream #0:0: Audio: mp3, 44100 Hz, stereo, s16p\n","    Metadata:\n","      encoder         : Lavc58.134.100 libmp3lame\n","size=       0kB time=00:00:00.00 bitrate=N/A speed=N/A    \rsize=      64kB time=00:00:03.99 bitrate= 130.1kbits/s speed=43.5x    \n","video:0kB audio:63kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.390535%\n"]}],"source":["!ffmpeg -i /content/alert.wav /content/alert.mp3"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":75},"executionInfo":{"elapsed":888,"status":"ok","timestamp":1737637607735,"user":{"displayName":"Kevin Harry","userId":"14407016036151746140"},"user_tz":-330},"id":"toRkwzFuRZd-","outputId":"bd59384f-490f-4a91-b862-488cb67f77f3"},"outputs":[{"data":{"text/html":["\n","                <audio  controls=\"controls\" autoplay=\"autoplay\">\n","                    <source src=\"data:audio/mpeg;base64,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\" type=\"audio/mpeg\" />\n","                    Your browser does not support the audio element.\n","                </audio>\n","              "],"text/plain":["<IPython.lib.display.Audio object>"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["from IPython.display import Audio\n","\n","# Play the converted audio file\n","Audio(\"/content/alert.mp3\", autoplay=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W4yXN4cTSCwF"},"outputs":[],"source":["def process_frame(self, frame):\n","    \"\"\"\n","    Process the frame and make a prediction.\n","    \"\"\"\n","    # Resize the frame to 224x224 pixels\n","    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","    image = Image.fromarray(image)\n","    image = ImageOps.fit(image, (224, 224), Image.Resampling.LANCZOS)\n","    image_array = np.asarray(image)\n","\n","    # Normalize the image\n","    normalized_image_array = (image_array.astype(np.float32) / 127.5) - 1\n","\n","    # Create a batch of one image\n","    data = np.expand_dims(normalized_image_array, axis=0)\n","\n","    # Perform prediction\n","    prediction = model.predict(data)\n","    index = np.argmax(prediction)\n","    class_name = class_names[index].strip()\n","    confidence_score = prediction[0][index]\n","\n","    # Check if the class is \"drowsy\"\n","    if class_name == \"drowsy\":\n","        self.drowsy_frame_count += 1\n","    else:\n","        self.drowsy_frame_count = 0  # Reset the counter if not drowsy\n","\n","    # Debug print to check predictions and drowsy frame count\n","    print(f\"Class: {class_name}, Confidence: {confidence_score:.2f}, Drowsy Frames: {self.drowsy_frame_count}\")\n","\n","    # Trigger alert if continuous drowsy frames exceed the threshold\n","    if self.drowsy_frame_count >= self.ALERT_THRESHOLD:\n","        print(\"ALERT: Drowsiness detected! Playing alert sound...\")\n","        display(Audio(alert_sound_file, autoplay=True))\n","        self.drowsy_frame_count = 0  # Reset the counter after alert\n","\n","    return class_name, confidence_score"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L1sEerVTSWji"},"outputs":[],"source":["def capture_frame_callback(image_data):\n","    \"\"\"\n","    Callback to process the captured image.\n","    \"\"\"\n","    if image_data is None:\n","        print(\"Error: No image data received.\")\n","        return\n","\n","    try:\n","        # Decode the image data\n","        image_bytes = base64.b64decode(image_data)\n","        frame = Image.open(io.BytesIO(image_bytes))\n","        frame = cv2.cvtColor(np.array(frame), cv2.COLOR_RGB2BGR)\n","\n","        # Debug print to verify frame capture\n","        print(\"Frame captured and processed.\")\n","\n","        # Process the frame\n","        class_name, confidence_score = drowsy_detector.process_frame(frame)\n","\n","        # Display the result\n","        cv2.putText(frame, f\"{class_name}: {confidence_score:.2f}\", (10, 30),\n","                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n","        cv2_imshow(frame)\n","    except Exception as e:\n","        print(f\"Error processing frame: {e}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"02wPgfPiSZd4"},"outputs":[],"source":["def process_frame(self, frame):\n","    \"\"\"\n","    Process the frame and make a prediction.\n","    \"\"\"\n","    # Resize the frame to 224x224 pixels\n","    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","    image = Image.fromarray(image)\n","    image = ImageOps.fit(image, (224, 224), Image.Resampling.LANCZOS)\n","    image_array = np.asarray(image)\n","\n","    # Normalize the image\n","    normalized_image_array = (image_array.astype(np.float32) / 127.5) - 1\n","\n","    # Create a batch of one image\n","    data = np.expand_dims(normalized_image_array, axis=0)\n","\n","    # Perform prediction\n","    prediction = model.predict(data)\n","    index = np.argmax(prediction)\n","    class_name = class_names[index].strip()\n","    confidence_score = prediction[0][index]\n","\n","    # Format confidence score as a whole number\n","    confidence_score_whole = int(confidence_score * 100)  # Convert to percentage and remove decimals\n","\n","    # Debug print to check predictions\n","    print(f\"Prediction: {prediction}\")\n","    print(f\"Class: {class_name}, Confidence: {confidence_score_whole}%\")\n","\n","    # Check if the class is \"drowsy\"\n","    if class_name == \"drowsy\":\n","        self.drowsy_frame_count += 1\n","        print(f\"Drowsy frame detected. Count: {self.drowsy_frame_count}\")\n","    else:\n","        self.drowsy_frame_count = 0  # Reset the counter if not drowsy\n","        print(\"Not drowsy. Resetting counter.\")\n","\n","    # Debug print to check drowsy frame count\n","    print(f\"Drowsy Frames: {self.drowsy_frame_count}\")\n","\n","    # Trigger alert if continuous drowsy frames exceed the threshold\n","    if self.drowsy_frame_count >= self.ALERT_THRESHOLD:\n","        print(\"ALERT: Drowsiness detected! Playing alert sound...\")\n","        display(Audio(alert_sound_file, autoplay=True))\n","\n","        # Display a popup message using JavaScript\n","        display(Javascript('alert(\"ALERT: Drowsiness detected! The driver is not responding.\");'))\n","\n","        self.drowsy_frame_count = 0  # Reset the counter after alert\n","\n","    return class_name, confidence_score_whole"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":390,"status":"ok","timestamp":1737641647071,"user":{"displayName":"Kevin Harry","userId":"14407016036151746140"},"user_tz":-330},"id":"MIvU3GXLg0r9","outputId":"c143342e-fd41-4421-b83c-df4d736330b5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drowsy frame detected. Count: 1\n"]}],"source":["import math\n","\n","# Simulate Vehicle Class\n","class Vehicle:\n","    def __init__(self, vehicle_id, location):\n","        self.vehicle_id = vehicle_id\n","        self.location = location  # (x, y) coordinates\n","        self.status = \"Active\"  # Status of the vehicle\n","\n","    def send_alert(self, message, vehicles):\n","        \"\"\"\n","        Send an alert to the nearest vehicle.\n","        \"\"\"\n","        nearest_vehicle = None\n","        min_distance = float('inf')\n","\n","        # Find the nearest vehicle\n","        for vehicle in vehicles:\n","            if vehicle.vehicle_id != self.vehicle_id:  # Skip itself\n","                distance = self.calculate_distance(vehicle.location)\n","                if distance < min_distance:\n","                    min_distance = distance\n","                    nearest_vehicle = vehicle\n","\n","        if nearest_vehicle:\n","            print(f\"Vehicle {self.vehicle_id} sending alert to Vehicle {nearest_vehicle.vehicle_id}: {message}\")\n","            nearest_vehicle.receive_alert(message)\n","        else:\n","            print(\"No nearby vehicles found to send the alert.\")\n","\n","    def receive_alert(self, message):\n","        \"\"\"\n","        Receive an alert from another vehicle.\n","        \"\"\"\n","        print(f\"Vehicle {self.vehicle_id} received alert: {message}\")\n","        self.status = \"Assisting\"  # Change status to assisting\n","\n","    def calculate_distance(self, other_location):\n","        \"\"\"\n","        Calculate Euclidean distance between two vehicles.\n","        \"\"\"\n","        return math.sqrt((self.location[0] - other_location[0]) ** 2 + (self.location[1] - other_location[1]) ** 2)\n","\n","# Simulate DrowsyDetector with V2V Communication\n","class DrowsyDetector:\n","    def __init__(self, vehicle, vehicles):\n","        self.vehicle = vehicle\n","        self.vehicles = vehicles\n","        self.drowsy_frame_count = 0\n","        self.ALERT_THRESHOLD = 5  # Number of continuous drowsy frames to trigger alert\n","\n","    def process_frame(self, frame):\n","        \"\"\"\n","        Simulate drowsiness detection and trigger V2V communication.\n","        \"\"\"\n","        # Simulate drowsiness detection (replace with actual logic)\n","        is_drowsy = self.simulate_drowsiness(frame)\n","\n","        if is_drowsy:\n","            self.drowsy_frame_count += 1\n","            print(f\"Drowsy frame detected. Count: {self.drowsy_frame_count}\")\n","        else:\n","            self.drowsy_frame_count = 0\n","            print(\"Not drowsy. Resetting counter.\")\n","\n","        # Trigger alert if continuous drowsy frames exceed the threshold\n","        if self.drowsy_frame_count >= self.ALERT_THRESHOLD:\n","            print(\"ALERT: Drowsiness detected! Sending alert to nearest vehicle...\")\n","            self.vehicle.send_alert(\"Driver is not responding. Need assistance!\", self.vehicles)\n","            self.drowsy_frame_count = 0  # Reset the counter after alert\n","\n","    def simulate_drowsiness(self, frame):\n","        \"\"\"\n","        Simulate drowsiness detection (replace with actual model prediction).\n","        \"\"\"\n","        # Replace this with actual model prediction logic\n","        return True  # Simulate drowsiness for testing\n","\n","# Simulate Vehicles\n","vehicle1 = Vehicle(vehicle_id=1, location=(0, 0))\n","vehicle2 = Vehicle(vehicle_id=2, location=(10, 10))\n","vehicle3 = Vehicle(vehicle_id=3, location=(20, 20))\n","\n","# List of vehicles\n","vehicles = [vehicle1, vehicle2, vehicle3]\n","\n","# Simulate DrowsyDetector for Vehicle 1\n","drowsy_detector = DrowsyDetector(vehicle1, vehicles)\n","\n","# Simulate a frame (replace with actual frame processing)\n","frame = \"simulated_frame\"\n","drowsy_detector.process_frame(frame)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":495},"executionInfo":{"elapsed":885,"status":"error","timestamp":1737697041527,"user":{"displayName":"Kevin Harry","userId":"14407016036151746140"},"user_tz":-330},"id":"rRxDGE3YhfGx","outputId":"8cbb481b-9a6d-40b9-88f0-401e46ff87fd"},"outputs":[{"ename":"TypeError","evalue":"Error when deserializing class 'DepthwiseConv2D' using config={'name': 'expanded_conv_depthwise', 'trainable': True, 'dtype': 'float32', 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'linear', 'use_bias': False, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_regularizer': None, 'activity_regularizer': None, 'bias_constraint': None, 'depth_multiplier': 1, 'depthwise_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'depthwise_regularizer': None, 'depthwise_constraint': None}.\n\nException encountered: Unrecognized keyword arguments passed to DepthwiseConv2D: {'groups': 1}","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/ops/operation.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/depthwise_conv2d.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, kernel_size, strides, padding, depth_multiplier, data_format, dilation_rate, activation, use_bias, depthwise_initializer, bias_initializer, depthwise_regularizer, bias_regularizer, activity_regularizer, depthwise_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     ):\n\u001b[0;32m--> 120\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_depthwise_conv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, rank, depth_multiplier, kernel_size, strides, padding, data_format, dilation_rate, activation, use_bias, depthwise_initializer, bias_initializer, depthwise_regularizer, bias_regularizer, activity_regularizer, depthwise_constraint, bias_constraint, trainable, name, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m     ):\n\u001b[0;32m--> 106\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    107\u001b[0m             \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, activity_regularizer, trainable, dtype, autocast, name, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    286\u001b[0m                 \u001b[0;34m\"Unrecognized keyword arguments \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Unrecognized keyword arguments passed to DepthwiseConv2D: {'groups': 1}","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-a5eb711f5a07>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Load the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/keras_model.h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Load and process labels correctly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    192\u001b[0m         )\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         return legacy_h5_format.load_model_from_hdf5(\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/legacy_h5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0msaving_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_option_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_legacy_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             model = saving_utils.model_from_config(\n\u001b[0m\u001b[1;32m    134\u001b[0m                 \u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/saving_utils.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_find_replace_nested_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"keras.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"keras.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     return serialization.deserialize_keras_object(\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMODULE_OBJECTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALL_OBJECTS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/serialization.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"custom_objects\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marg_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m                 deserialized_obj = cls.from_config(\n\u001b[0m\u001b[1;32m    496\u001b[0m                     \u001b[0mcls_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m                     custom_objects={\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/sequential.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    343\u001b[0m                 \u001b[0;31m# Legacy format deserialization (no \"module\" key)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m                 \u001b[0;31m# used for H5 and SavedModel formats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m                 layer = saving_utils.model_from_config(\n\u001b[0m\u001b[1;32m    346\u001b[0m                     \u001b[0mlayer_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/saving_utils.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_find_replace_nested_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"keras.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"keras.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     return serialization.deserialize_keras_object(\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMODULE_OBJECTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALL_OBJECTS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/serialization.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"custom_objects\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marg_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m                 deserialized_obj = cls.from_config(\n\u001b[0m\u001b[1;32m    496\u001b[0m                     \u001b[0mcls_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m                     custom_objects={\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/sequential.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    343\u001b[0m                 \u001b[0;31m# Legacy format deserialization (no \"module\" key)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m                 \u001b[0;31m# used for H5 and SavedModel formats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m                 layer = saving_utils.model_from_config(\n\u001b[0m\u001b[1;32m    346\u001b[0m                     \u001b[0mlayer_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/saving_utils.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_find_replace_nested_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"keras.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"keras.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     return serialization.deserialize_keras_object(\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMODULE_OBJECTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALL_OBJECTS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/serialization.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"custom_objects\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marg_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m                 deserialized_obj = cls.from_config(\n\u001b[0m\u001b[1;32m    496\u001b[0m                     \u001b[0mcls_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m                     custom_objects={\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/model.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional_from_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m             return functional_from_config(\n\u001b[0m\u001b[1;32m    526\u001b[0m                 \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py\u001b[0m in \u001b[0;36mfunctional_from_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[0;31m# First, we create all layers and enqueue nodes to be processed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"layers\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m         \u001b[0mprocess_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;31m# Then we process nodes in order of layer depth.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py\u001b[0m in \u001b[0;36mprocess_layer\u001b[0;34m(layer_data)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Legacy format deserialization (no \"module\" key)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# used for H5 and SavedModel formats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             layer = saving_utils.model_from_config(\n\u001b[0m\u001b[1;32m    458\u001b[0m                 \u001b[0mlayer_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/saving_utils.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_find_replace_nested_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"keras.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"keras.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     return serialization.deserialize_keras_object(\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMODULE_OBJECTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALL_OBJECTS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/serialization.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mobject_registration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m                     \u001b[0mdeserialized_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m             \u001b[0;31m# Then `cls` may be a function returning a class.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/ops/operation.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m             raise TypeError(\n\u001b[0m\u001b[1;32m    237\u001b[0m                 \u001b[0;34mf\"Error when deserializing class '{cls.__name__}' using \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;34mf\"config={config}.\\n\\nException encountered: {e}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Error when deserializing class 'DepthwiseConv2D' using config={'name': 'expanded_conv_depthwise', 'trainable': True, 'dtype': 'float32', 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'linear', 'use_bias': False, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_regularizer': None, 'activity_regularizer': None, 'bias_constraint': None, 'depth_multiplier': 1, 'depthwise_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'depthwise_regularizer': None, 'depthwise_constraint': None}.\n\nException encountered: Unrecognized keyword arguments passed to DepthwiseConv2D: {'groups': 1}"]}],"source":["import cv2\n","import numpy as np\n","from keras.models import load_model\n","from PIL import Image, ImageOps\n","from google.colab.patches import cv2_imshow\n","from google.colab import output\n","import base64\n","import io\n","from IPython.display import display, Javascript, Audio\n","import math\n","\n","# Load the model\n","model = load_model(\"/content/keras_model.h5\", compile=False)\n","\n","# Load and process labels correctly\n","with open(\"/content/labels.txt\", \"r\") as f:\n","    class_names = [line.strip().split(' ', 1)[1] for line in f.readlines()]\n","\n","# Path to the alert sound file (converted to .mp3)\n","alert_sound_file = \"/content/alert.mp3\"\n","\n","# Simulate Vehicle Class\n","class Vehicle:\n","    def __init__(self, vehicle_id, location):\n","        self.vehicle_id = vehicle_id\n","        self.location = location  # (x, y) coordinates\n","        self.status = \"Active\"  # Status of the vehicle\n","\n","    def send_alert(self, message, vehicles):\n","        \"\"\"\n","        Send an alert to the nearest vehicle.\n","        \"\"\"\n","        nearest_vehicle = None\n","        min_distance = float('inf')\n","\n","        # Find the nearest vehicle\n","        for vehicle in vehicles:\n","            if vehicle.vehicle_id != self.vehicle_id:  # Skip itself\n","                distance = self.calculate_distance(vehicle.location)\n","                if distance < min_distance:\n","                    min_distance = distance\n","                    nearest_vehicle = vehicle\n","\n","        if nearest_vehicle:\n","            print(f\"Vehicle {self.vehicle_id} sending alert to Vehicle {nearest_vehicle.vehicle_id}: {message}\")\n","            nearest_vehicle.receive_alert(message)\n","        else:\n","            print(\"No nearby vehicles found to send the alert.\")\n","\n","    def receive_alert(self, message):\n","        \"\"\"\n","        Receive an alert from another vehicle.\n","        \"\"\"\n","        print(f\"Vehicle {self.vehicle_id} received alert: {message}\")\n","        self.status = \"Assisting\"  # Change status to assisting\n","\n","    def calculate_distance(self, other_location):\n","        \"\"\"\n","        Calculate Euclidean distance between two vehicles.\n","        \"\"\"\n","        return math.sqrt((self.location[0] - other_location[0]) ** 2 + (self.location[1] - other_location[1]) ** 2)\n","\n","# Simulate Vehicles\n","vehicle1 = Vehicle(vehicle_id=1, location=(0, 0))\n","vehicle2 = Vehicle(vehicle_id=2, location=(10, 10))\n","vehicle3 = Vehicle(vehicle_id=3, location=(20, 20))\n","\n","# List of vehicles\n","vehicles = [vehicle1, vehicle2, vehicle3]\n","\n","# Class to maintain state\n","class DrowsyDetector:\n","    def __init__(self, vehicle, vehicles):\n","        self.vehicle = vehicle\n","        self.vehicles = vehicles\n","        self.drowsy_frame_count = 0\n","        self.ALERT_THRESHOLD = 10  # Number of continuous drowsy frames to trigger alert\n","\n","    def process_frame(self, frame):\n","        \"\"\"\n","        Process the frame and make a prediction.\n","        \"\"\"\n","        # Resize the frame to 224x224 pixels\n","        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","        image = Image.fromarray(image)\n","        image = ImageOps.fit(image, (224, 224), Image.Resampling.LANCZOS)\n","        image_array = np.asarray(image)\n","\n","        # Normalize the image\n","        normalized_image_array = (image_array.astype(np.float32) / 127.5) - 1\n","\n","        # Create a batch of one image\n","        data = np.expand_dims(normalized_image_array, axis=0)\n","\n","        # Perform prediction\n","        prediction = model.predict(data)\n","        index = np.argmax(prediction)\n","        class_name = class_names[index]\n","        confidence_score = prediction[0][index]\n","\n","        # Format confidence score as a whole number\n","        confidence_score_whole = int(confidence_score * 100)\n","\n","        # Check if the class is \"Drowsy\" (index 0)\n","        if index == 0:  # Directly check the index instead of class name string\n","            self.drowsy_frame_count += 1\n","            print(f\"Drowsy frame detected. Count: {self.drowsy_frame_count}\")\n","        else:\n","            self.drowsy_frame_count = 0\n","            print(\"Not drowsy. Resetting counter.\")\n","\n","        # Trigger alert if continuous drowsy frames exceed the threshold\n","        if self.drowsy_frame_count >= self.ALERT_THRESHOLD:\n","            print(\"ALERT: Drowsiness detected! Sending alert to nearest vehicle...\")\n","            self.vehicle.send_alert(\"Driver is not responding. Need assistance!\", self.vehicles)\n","            display(Audio(alert_sound_file, autoplay=True))  # Play alert sound\n","            self.drowsy_frame_count = 0  # Reset the counter after alert\n","\n","        return class_name, confidence_score_whole\n","\n","# Create an instance of the DrowsyDetector class\n","drowsy_detector = DrowsyDetector(vehicle1, vehicles)\n","\n","def capture_image():\n","    \"\"\"\n","    Function to capture an image from the webcam via JavaScript.\n","    \"\"\"\n","    js = Javascript('''\n","        async function takePhoto() {\n","            const div = document.createElement('div');\n","            const video = document.createElement('video');\n","            const canvas = document.createElement('canvas');\n","            const button = document.createElement('button');\n","            button.textContent = 'Stop';\n","\n","            div.appendChild(video);\n","            div.appendChild(button);\n","            document.body.appendChild(div);\n","\n","            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n","            video.srcObject = stream;\n","            await video.play();\n","\n","            return new Promise((resolve) => {\n","                button.onclick = () => {\n","                    stream.getTracks().forEach(track => track.stop());\n","                    div.remove();\n","                };\n","\n","                setInterval(async () => {\n","                    if (!video.srcObject.active) {\n","                        resolve(null);\n","                        return;\n","                    }\n","                    canvas.width = video.videoWidth;\n","                    canvas.height = video.videoHeight;\n","                    canvas.getContext('2d').drawImage(video, 0, 0);\n","                    const data = canvas.toDataURL('image/jpeg').split(',')[1];\n","                    google.colab.kernel.invokeFunction('notebook.captureFrameCallback', [data], {});\n","                }, 1000); // Capture every second\n","            });\n","        }\n","        takePhoto();\n","    ''')\n","    display(js)\n","\n","def capture_frame_callback(image_data):\n","    \"\"\"\n","    Callback to process the captured image.\n","    \"\"\"\n","    if image_data is None:\n","        print(\"Error: No image data received.\")\n","        return\n","\n","    try:\n","        # Decode the image data\n","        image_bytes = base64.b64decode(image_data)\n","        frame = Image.open(io.BytesIO(image_bytes))\n","        frame = cv2.cvtColor(np.array(frame), cv2.COLOR_RGB2BGR)\n","\n","        # Process the frame\n","        class_name, confidence_score_whole = drowsy_detector.process_frame(frame)\n","\n","        # Add drowsiness details to the frame\n","        text = f\"Class: {class_name}\\nConfidence: {confidence_score_whole}%\\nDrowsy Frames: {drowsy_detector.drowsy_frame_count}\"\n","\n","        # Position the text on the right side of the frame\n","        text_x = frame.shape[1] - 300\n","        text_y = 50\n","        font = cv2.FONT_HERSHEY_SIMPLEX\n","        font_scale = 0.8\n","        font_color = (0, 255, 0)\n","        font_thickness = 2\n","\n","        # Split the text into lines\n","        lines = text.split('\\n')\n","        for i, line in enumerate(lines):\n","            y = text_y + i * 30\n","            cv2.putText(frame, line, (text_x, y), font, font_scale, font_color, font_thickness, cv2.LINE_AA)\n","\n","        # Display the result\n","        cv2_imshow(frame)\n","    except Exception as e:\n","        print(f\"Error processing frame: {e}\")\n","\n","# Register callback function\n","output.register_callback('notebook.captureFrameCallback', capture_frame_callback)\n","\n","# Start capturing\n","capture_image()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"executionInfo":{"elapsed":390,"status":"error","timestamp":1737789119255,"user":{"displayName":"Kevin Harry","userId":"14407016036151746140"},"user_tz":-330},"id":"o2rIDyWUjNSK","outputId":"9f1f0e2a-a8cd-4a41-955d-8a23314f802a"},"outputs":[{"ename":"TypeError","evalue":"Error when deserializing class 'DepthwiseConv2D' using config={'name': 'expanded_conv_depthwise', 'trainable': True, 'dtype': 'float32', 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'linear', 'use_bias': False, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_regularizer': None, 'activity_regularizer': None, 'bias_constraint': None, 'depth_multiplier': 1, 'depthwise_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'depthwise_regularizer': None, 'depthwise_constraint': None}.\n\nException encountered: Unrecognized keyword arguments passed to DepthwiseConv2D: {'groups': 1}","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/ops/operation.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/depthwise_conv2d.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, kernel_size, strides, padding, depth_multiplier, data_format, dilation_rate, activation, use_bias, depthwise_initializer, bias_initializer, depthwise_regularizer, bias_regularizer, activity_regularizer, depthwise_constraint, bias_constraint, **kwargs)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_depthwise_conv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, rank, depth_multiplier, kernel_size, strides, padding, data_format, dilation_rate, activation, use_bias, depthwise_initializer, bias_initializer, depthwise_regularizer, bias_regularizer, activity_regularizer, depthwise_constraint, bias_constraint, trainable, name, **kwargs)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, activity_regularizer, trainable, dtype, autocast, name, **kwargs)\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Unrecognized keyword arguments passed to DepthwiseConv2D: {'groups': 1}","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-090b19b61946>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Load the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/keras_model.h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Load and process labels correctly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/legacy_h5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/saving_utils.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/serialization.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/sequential.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/saving_utils.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/serialization.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/sequential.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/saving_utils.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/serialization.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/model.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py\u001b[0m in \u001b[0;36mfunctional_from_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py\u001b[0m in \u001b[0;36mprocess_layer\u001b[0;34m(layer_data)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/saving_utils.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/serialization.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/ops/operation.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config)\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Error when deserializing class 'DepthwiseConv2D' using config={'name': 'expanded_conv_depthwise', 'trainable': True, 'dtype': 'float32', 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'groups': 1, 'activation': 'linear', 'use_bias': False, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'bias_regularizer': None, 'activity_regularizer': None, 'bias_constraint': None, 'depth_multiplier': 1, 'depthwise_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'depthwise_regularizer': None, 'depthwise_constraint': None}.\n\nException encountered: Unrecognized keyword arguments passed to DepthwiseConv2D: {'groups': 1}"]}],"source":["import cv2\n","import numpy as np\n","from keras.models import load_model\n","from PIL import Image, ImageOps\n","from google.colab.patches import cv2_imshow\n","from google.colab import output\n","import base64\n","import io\n","from IPython.display import display, Javascript, Audio\n","import math\n","\n","# Load the model\n","model = load_model(\"/content/keras_model.h5\", compile=False)\n","\n","# Load and process labels correctly\n","with open(\"/content/labels.txt\", \"r\") as f:\n","    class_names = [line.strip().split(' ', 1)[1] for line in f.readlines()]\n","\n","# Path to the alert sound file (converted to .mp3)\n","alert_sound_file = \"/content/alert.mp3\"\n","\n","# Simulate Vehicle Class\n","class Vehicle:\n","    def __init__(self, vehicle_id, location):\n","        self.vehicle_id = vehicle_id\n","        self.location = location  # (x, y) coordinates\n","        self.status = \"Active\"  # Status of the vehicle\n","\n","    def send_alert(self, message, vehicles):\n","        \"\"\"\n","        Send an alert to the nearest vehicle.\n","        \"\"\"\n","        nearest_vehicle = None\n","        min_distance = float('inf')\n","\n","        # Find the nearest vehicle\n","        for vehicle in vehicles:\n","            if vehicle.vehicle_id != self.vehicle_id:  # Skip itself\n","                distance = self.calculate_distance(vehicle.location)\n","                if distance < min_distance:\n","                    min_distance = distance\n","                    nearest_vehicle = vehicle\n","\n","        if nearest_vehicle:\n","            print(f\"Vehicle {self.vehicle_id} sending alert to Vehicle {nearest_vehicle.vehicle_id}: {message}\")\n","            nearest_vehicle.receive_alert(message)\n","        else:\n","            print(\"No nearby vehicles found to send the alert.\")\n","\n","    def receive_alert(self, message):\n","        \"\"\"\n","        Receive an alert from another vehicle.\n","        \"\"\"\n","        print(f\"Vehicle {self.vehicle_id} received alert: {message}\")\n","        self.status = \"Assisting\"  # Change status to assisting\n","\n","    def calculate_distance(self, other_location):\n","        \"\"\"\n","        Calculate Euclidean distance between two vehicles.\n","        \"\"\"\n","        return math.sqrt((self.location[0] - other_location[0]) ** 2 + (self.location[1] - other_location[1]) ** 2)\n","\n","# Simulate Vehicles\n","vehicle1 = Vehicle(vehicle_id=1, location=(0, 0))\n","vehicle2 = Vehicle(vehicle_id=2, location=(10, 10))\n","vehicle3 = Vehicle(vehicle_id=3, location=(20, 20))\n","\n","# List of vehicles\n","vehicles = [vehicle1, vehicle2, vehicle3]\n","\n","# Class to maintain state\n","class DrowsyDetector:\n","    def __init__(self, vehicle, vehicles):\n","        self.vehicle = vehicle\n","        self.vehicles = vehicles\n","        self.drowsy_frame_count = 0\n","        self.ALERT_THRESHOLD = 5  # Number of continuous drowsy frames to trigger alert sound\n","        self.V2V_THRESHOLD = 10  # Number of continuous drowsy frames to trigger V2V communication\n","\n","    def process_frame(self, frame):\n","        \"\"\"\n","        Process the frame and make a prediction.\n","        \"\"\"\n","        # Resize the frame to 224x224 pixels\n","        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","        image = Image.fromarray(image)\n","        image = ImageOps.fit(image, (224, 224), Image.Resampling.LANCZOS)\n","        image_array = np.asarray(image)\n","\n","        # Normalize the image\n","        normalized_image_array = (image_array.astype(np.float32) / 127.5) - 1\n","\n","        # Create a batch of one image\n","        data = np.expand_dims(normalized_image_array, axis=0)\n","\n","        # Perform prediction\n","        prediction = model.predict(data)\n","        index = np.argmax(prediction)\n","        class_name = class_names[index]\n","        confidence_score = prediction[0][index]\n","\n","        # Format confidence score as a whole number\n","        confidence_score_whole = int(confidence_score * 100)\n","\n","        # Check if the class is \"Drowsy\" (index 0)\n","        if index == 0:  # Directly check the index instead of class name string\n","            self.drowsy_frame_count += 1\n","            print(f\"Drowsy frame detected. Count: {self.drowsy_frame_count}\")\n","        else:\n","            self.drowsy_frame_count = 0\n","            print(\"Not drowsy. Resetting counter.\")\n","\n","        # Trigger alert sound if continuous drowsy frames exceed the alert threshold\n","        if self.drowsy_frame_count >= self.ALERT_THRESHOLD and self.drowsy_frame_count < self.V2V_THRESHOLD:\n","            print(\"ALERT: Drowsiness detected! Playing alert sound...\")\n","            display(Audio(alert_sound_file, autoplay=True))  # Play alert sound\n","\n","        # Trigger V2V communication if continuous drowsy frames exceed the V2V threshold\n","        if self.drowsy_frame_count >= self.V2V_THRESHOLD:\n","            print(\"ALERT: Drowsiness detected! Sending alert to nearest vehicle...\")\n","            self.vehicle.send_alert(\"Driver is not responding. Need assistance!\", self.vehicles)\n","            display(Javascript('alert(\"V2V Communication: Alert sent to nearest vehicle.\");'))  # Popup for V2V\n","            self.drowsy_frame_count = 0  # Reset the counter after alert\n","\n","        return class_name, confidence_score_whole\n","\n","# Create an instance of the DrowsyDetector class\n","drowsy_detector = DrowsyDetector(vehicle1, vehicles)\n","\n","def capture_image():\n","    \"\"\"\n","    Function to capture an image from the webcam via JavaScript.\n","    \"\"\"\n","    js = Javascript('''\n","        async function takePhoto() {\n","            const div = document.createElement('div');\n","            const video = document.createElement('video');\n","            const canvas = document.createElement('canvas');\n","            const button = document.createElement('button');\n","            button.textContent = 'Stop';\n","\n","            div.appendChild(video);\n","            div.appendChild(button);\n","            document.body.appendChild(div);\n","\n","            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n","            video.srcObject = stream;\n","            await video.play();\n","\n","            return new Promise((resolve) => {\n","                button.onclick = () => {\n","                    stream.getTracks().forEach(track => track.stop());\n","                    div.remove();\n","                };\n","\n","                setInterval(async () => {\n","                    if (!video.srcObject.active) {\n","                        resolve(null);\n","                        return;\n","                    }\n","                    canvas.width = video.videoWidth;\n","                    canvas.height = video.videoHeight;\n","                    canvas.getContext('2d').drawImage(video, 0, 0);\n","                    const data = canvas.toDataURL('image/jpeg').split(',')[1];\n","                    google.colab.kernel.invokeFunction('notebook.captureFrameCallback', [data], {});\n","                }, 1000); // Capture every second\n","            });\n","        }\n","        takePhoto();\n","    ''')\n","    display(js)\n","\n","def capture_frame_callback(image_data):\n","    \"\"\"\n","    Callback to process the captured image.\n","    \"\"\"\n","    if image_data is None:\n","        print(\"Error: No image data received.\")\n","        return\n","\n","    try:\n","        # Decode the image data\n","        image_bytes = base64.b64decode(image_data)\n","        frame = Image.open(io.BytesIO(image_bytes))\n","        frame = cv2.cvtColor(np.array(frame), cv2.COLOR_RGB2BGR)\n","\n","        # Process the frame\n","        class_name, confidence_score_whole = drowsy_detector.process_frame(frame)\n","\n","        # Add drowsiness details to the frame\n","        text = f\"Class: {class_name}\\nConfidence: {confidence_score_whole}%\\nDrowsy Frames: {drowsy_detector.drowsy_frame_count}\"\n","\n","        # Position the text on the right side of the frame\n","        text_x = frame.shape[1] - 300\n","        text_y = 50\n","        font = cv2.FONT_HERSHEY_SIMPLEX\n","        font_scale = 0.8\n","        font_color = (0, 255, 0)\n","        font_thickness = 2\n","\n","        # Split the text into lines\n","        lines = text.split('\\n')\n","        for i, line in enumerate(lines):\n","            y = text_y + i * 30\n","            cv2.putText(frame, line, (text_x, y), font, font_scale, font_color, font_thickness, cv2.LINE_AA)\n","\n","        # Display the result\n","        cv2_imshow(frame)\n","    except Exception as e:\n","        print(f\"Error processing frame: {e}\")\n","\n","# Register callback function\n","output.register_callback('notebook.captureFrameCallback', capture_frame_callback)\n","\n","# Start capturing\n","capture_image()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1i5NlhnVLZqwWeC6XM2C8k8jyf81AclBK"},"executionInfo":{"elapsed":3895,"status":"ok","timestamp":1737776406545,"user":{"displayName":"Kevin Harry","userId":"14407016036151746140"},"user_tz":-330},"id":"6FBq4S5Bi4KM","outputId":"bbdf5d79-dab3-4834-b873-d28a8bfd2d93"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["import cv2\n","import numpy as np\n","from keras.models import load_model\n","from PIL import Image, ImageOps\n","from google.colab.patches import cv2_imshow\n","from google.colab import output\n","import base64\n","import io\n","from IPython.display import display, Javascript, Audio\n","import math\n","import time\n","\n","# Load the model\n","model = load_model(\"/content/keras_model.h5\", compile=False)\n","\n","# Load and process labels correctly\n","with open(\"/content/labels.txt\", \"r\") as f:\n","    class_names = [line.strip().split(' ', 1)[1] for line in f.readlines()]\n","\n","# Path to the alert sound file (converted to .mp3)\n","alert_sound_file = \"/content/alert.mp3\"\n","\n","# Simulate Vehicle Class\n","class Vehicle:\n","    def __init__(self, vehicle_id, location):\n","        self.vehicle_id = vehicle_id\n","        self.location = location  # (x, y) coordinates\n","        self.status = \"Active\"  # Status of the vehicle\n","\n","    def send_alert(self, message, vehicles):\n","        \"\"\"\n","        Send an alert to the nearest vehicle.\n","        \"\"\"\n","        nearest_vehicle = None\n","        min_distance = float('inf')\n","\n","        # Find the nearest vehicle\n","        for vehicle in vehicles:\n","            if vehicle.vehicle_id != self.vehicle_id:  # Skip itself\n","                distance = self.calculate_distance(vehicle.location)\n","                if distance < min_distance:\n","                    min_distance = distance\n","                    nearest_vehicle = vehicle\n","\n","        if nearest_vehicle:\n","            print(f\"Vehicle {self.vehicle_id} sending alert to Vehicle {nearest_vehicle.vehicle_id}: {message}\")\n","            nearest_vehicle.receive_alert(message)\n","        else:\n","            print(\"No nearby vehicles found to send the alert.\")\n","\n","    def receive_alert(self, message):\n","        \"\"\"\n","        Receive an alert from another vehicle.\n","        \"\"\"\n","        print(f\"Vehicle {self.vehicle_id} received alert: {message}\")\n","        self.status = \"Assisting\"  # Change status to assisting\n","\n","    def calculate_distance(self, other_location):\n","        \"\"\"\n","        Calculate Euclidean distance between two vehicles.\n","        \"\"\"\n","        return math.sqrt((self.location[0] - other_location[0]) ** 2 + (self.location[1] - other_location[1]) ** 2)\n","\n","# Simulate Vehicles\n","vehicle1 = Vehicle(vehicle_id=1, location=(0, 0))\n","vehicle2 = Vehicle(vehicle_id=2, location=(10, 10))\n","vehicle3 = Vehicle(vehicle_id=3, location=(20, 20))\n","\n","# List of vehicles\n","vehicles = [vehicle1, vehicle2, vehicle3]\n","\n","# Class to maintain state\n","class DrowsyDetector:\n","    def __init__(self, vehicle, vehicles):\n","        self.vehicle = vehicle\n","        self.vehicles = vehicles\n","        self.drowsy_frame_count = 0\n","        self.non_drowsy_frame_count = 0\n","        self.longest_drowsy_streak = 0\n","        self.longest_non_drowsy_streak = 0\n","        self.total_drowsy_frames = 0\n","        self.total_non_drowsy_frames = 0\n","        self.start_time = time.time()\n","        self.ALERT_THRESHOLD = 5  # Number of continuous drowsy frames to trigger alert sound\n","        self.V2V_THRESHOLD = 10  # Number of continuous drowsy frames to trigger V2V communication\n","\n","    def process_frame(self, frame):\n","        \"\"\"\n","        Process the frame and make a prediction.\n","        \"\"\"\n","        # Resize the frame to 224x224 pixels\n","        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","        image = Image.fromarray(image)\n","        image = ImageOps.fit(image, (224, 224), Image.Resampling.LANCZOS)\n","        image_array = np.asarray(image)\n","\n","        # Normalize the image\n","        normalized_image_array = (image_array.astype(np.float32) / 127.5) - 1\n","\n","        # Create a batch of one image\n","        data = np.expand_dims(normalized_image_array, axis=0)\n","\n","        # Perform prediction\n","        prediction = model.predict(data)\n","        index = np.argmax(prediction)\n","        class_name = class_names[index]\n","        confidence_score = prediction[0][index]\n","\n","        # Format confidence score as a whole number\n","        confidence_score_whole = int(confidence_score * 100)\n","\n","        # Check if the class is \"Drowsy\" (index 0)\n","        if index == 0:  # Directly check the index instead of class name string\n","            self.drowsy_frame_count += 1\n","            self.total_drowsy_frames += 1\n","            if self.drowsy_frame_count > self.longest_drowsy_streak:\n","                self.longest_drowsy_streak = self.drowsy_frame_count\n","            self.non_drowsy_frame_count = 0\n","            print(f\"Drowsy frame detected. Count: {self.drowsy_frame_count}\")\n","        else:\n","            self.non_drowsy_frame_count += 1\n","            self.total_non_drowsy_frames += 1\n","            if self.non_drowsy_frame_count > self.longest_non_drowsy_streak:\n","                self.longest_non_drowsy_streak = self.non_drowsy_frame_count\n","            self.drowsy_frame_count = 0\n","            print(\"Not drowsy. Resetting drowsy counter.\")\n","\n","        # Trigger alert sound if continuous drowsy frames exceed the alert threshold\n","        if self.drowsy_frame_count >= self.ALERT_THRESHOLD and self.drowsy_frame_count < self.V2V_THRESHOLD:\n","            print(\"ALERT: Drowsiness detected! Playing alert sound...\")\n","            display(Audio(alert_sound_file, autoplay=True))  # Play alert sound\n","\n","        # Trigger V2V communication if continuous drowsy frames exceed the V2V threshold\n","        if self.drowsy_frame_count >= self.V2V_THRESHOLD:\n","            print(\"ALERT: Drowsiness detected! Sending alert to nearest vehicle...\")\n","            self.vehicle.send_alert(\"Driver is not responding. Need assistance!\", self.vehicles)\n","            display(Javascript('alert(\"V2V Communication: Alert sent to nearest vehicle.\");'))  # Popup for V2V\n","            self.drowsy_frame_count = 0  # Reset the counter after alert\n","\n","        return class_name, confidence_score_whole\n","\n","    def get_final_stats(self):\n","        \"\"\"\n","        Get final statistics when the webcam is stopped.\n","        \"\"\"\n","        end_time = time.time()\n","        total_time = end_time - self.start_time\n","\n","        stats = {\n","            \"total_drowsy_frames\": self.total_drowsy_frames,\n","            \"total_non_drowsy_frames\": self.total_non_drowsy_frames,\n","            \"longest_drowsy_streak\": self.longest_drowsy_streak,\n","            \"longest_non_drowsy_streak\": self.longest_non_drowsy_streak,\n","            \"total_time\": total_time\n","        }\n","\n","        return stats\n","\n","# Create an instance of the DrowsyDetector class\n","drowsy_detector = DrowsyDetector(vehicle1, vehicles)\n","\n","def capture_image():\n","    \"\"\"\n","    Function to capture an image from the webcam via JavaScript.\n","    \"\"\"\n","    js = Javascript('''\n","        async function takePhoto() {\n","            const div = document.createElement('div');\n","            const video = document.createElement('video');\n","            const canvas = document.createElement('canvas');\n","            const button = document.createElement('button');\n","            button.textContent = 'Stop';\n","\n","            div.appendChild(video);\n","            div.appendChild(button);\n","            document.body.appendChild(div);\n","\n","            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n","            video.srcObject = stream;\n","            await video.play();\n","\n","            return new Promise((resolve) => {\n","                button.onclick = () => {\n","                    stream.getTracks().forEach(track => track.stop());\n","                    div.remove();\n","                    resolve(null);\n","                };\n","\n","                setInterval(async () => {\n","                    if (!video.srcObject.active) {\n","                        resolve(null);\n","                        return;\n","                    }\n","                    canvas.width = video.videoWidth;\n","                    canvas.height = video.videoHeight;\n","                    canvas.getContext('2d').drawImage(video, 0, 0);\n","                    const data = canvas.toDataURL('image/jpeg').split(',')[1];\n","                    google.colab.kernel.invokeFunction('notebook.captureFrameCallback', [data], {});\n","                }, 1000); // Capture every second\n","            });\n","        }\n","        takePhoto();\n","    ''')\n","    display(js)\n","\n","def capture_frame_callback(image_data):\n","    \"\"\"\n","    Callback to process the captured image.\n","    \"\"\"\n","    if image_data is None:\n","        print(\"Stopping webcam...\")\n","        stats = drowsy_detector.get_final_stats()\n","        print(\"\\nFinal Statistics:\")\n","        print(f\"Total Drowsy Frames: {stats['total_drowsy_frames']}\")\n","        print(f\"Total Non-Drowsy Frames: {stats['total_non_drowsy_frames']}\")\n","        print(f\"Longest Drowsy Streak: {stats['longest_drowsy_streak']} frames\")\n","        print(f\"Longest Non-Drowsy Streak: {stats['longest_non_drowsy_streak']} frames\")\n","        print(f\"Total Time: {stats['total_time']:.2f} seconds\")\n","\n","        # Create a blank frame to display the final statistics\n","        frame = np.zeros((500, 800, 3), dtype=np.uint8)  # Black background\n","\n","        # Add statistics to the frame\n","        text = [\n","            \"Final Statistics:\",\n","            \"-----------------\",\n","            f\"Total Drowsy Frames: {stats['total_drowsy_frames']}\",\n","            f\"Total Non-Drowsy Frames: {stats['total_non_drowsy_frames']}\",\n","            f\"Longest Drowsy Streak: {stats['longest_drowsy_streak']} frames\",\n","            f\"Longest Non-Drowsy Streak: {stats['longest_non_drowsy_streak']} frames\",\n","            f\"Total Time: {stats['total_time']:.2f} seconds\"\n","        ]\n","\n","        # Position the text on the left side of the frame\n","        text_x = 50\n","        text_y = 50\n","        font = cv2.FONT_HERSHEY_SIMPLEX\n","        font_scale = 0.8\n","        font_color = (0, 255, 0)  # Green color\n","        font_thickness = 2\n","\n","        # Add each line of text to the frame\n","        for i, line in enumerate(text):\n","            y = text_y + i * 30\n","            cv2.putText(frame, line, (text_x, y), font, font_scale, font_color, font_thickness, cv2.LINE_AA)\n","\n","        # Display the final frame with statistics\n","        cv2_imshow(frame)\n","        return\n","\n","    try:\n","        # Decode the image data\n","        image_bytes = base64.b64decode(image_data)\n","        frame = Image.open(io.BytesIO(image_bytes))\n","        frame = cv2.cvtColor(np.array(frame), cv2.COLOR_RGB2BGR)\n","\n","        # Process the frame\n","        class_name, confidence_score_whole = drowsy_detector.process_frame(frame)\n","\n","        # Add drowsiness details to the frame\n","        text = f\"Class: {class_name}\\nConfidence: {confidence_score_whole}%\\nDrowsy Frames: {drowsy_detector.drowsy_frame_count}\\nNon-Drowsy Frames: {drowsy_detector.non_drowsy_frame_count}\"\n","\n","        # Position the text on the right side of the frame\n","        text_x = frame.shape[1] - 300\n","        text_y = 50\n","        font = cv2.FONT_HERSHEY_SIMPLEX\n","        font_scale = 0.8\n","        font_color = (0, 255, 0)\n","        font_thickness = 2\n","\n","        # Split the text into lines\n","        lines = text.split('\\n')\n","        for i, line in enumerate(lines):\n","            y = text_y + i * 30\n","            cv2.putText(frame, line, (text_x, y), font, font_scale, font_color, font_thickness, cv2.LINE_AA)\n","\n","        # Display the result\n","        cv2_imshow(frame)\n","    except Exception as e:\n","        print(f\"Error processing frame: {e}\")\n","\n","# Register callback function\n","output.register_callback('notebook.captureFrameCallback', capture_frame_callback)\n","\n","# Start capturing\n","capture_image()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":90},"executionInfo":{"elapsed":47892,"status":"ok","timestamp":1737865189768,"user":{"displayName":"Kevin Harry","userId":"14407016036151746140"},"user_tz":-330},"id":"h2fgL_tEltyN","outputId":"f96bce0f-055e-4160-f205-0714cf2407ec"},"outputs":[{"data":{"text/html":["\n","     <input type=\"file\" id=\"files-78eb4db3-dfc0-4582-9f25-2d3e9cddf13d\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-78eb4db3-dfc0-4582-9f25-2d3e9cddf13d\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Saving New folder.zip to New folder.zip\n","Uploaded New folder.zip\n"]}],"source":["from google.colab import files\n","\n","# Upload the V2V Communication files\n","uploaded = files.upload()\n","\n","# List the uploaded files\n","for filename in uploaded.keys():\n","    print(f\"Uploaded {filename}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UdgIX9UmmSf7"},"outputs":[],"source":["import subprocess\n","\n","# Start the V2V server\n","v2v_server_process = subprocess.Popen([\"python\", \"v2v_server.py\"])\n","\n","# Start the Traffic Police server\n","traffic_police_server_process = subprocess.Popen([\"python\", \"traffic_police_server.py\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17211,"status":"ok","timestamp":1737865261834,"user":{"displayName":"Kevin Harry","userId":"14407016036151746140"},"user_tz":-330},"id":"HcZKwxG8mujA","outputId":"f3eac385-0afb-4a05-a91a-3835af1be0c3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting python-socketio\n","  Downloading python_socketio-5.12.1-py3-none-any.whl.metadata (3.2 kB)\n","Collecting bidict>=0.21.0 (from python-socketio)\n","  Downloading bidict-0.23.1-py3-none-any.whl.metadata (8.7 kB)\n","Collecting python-engineio>=4.11.0 (from python-socketio)\n","  Downloading python_engineio-4.11.2-py3-none-any.whl.metadata (2.2 kB)\n","Collecting simple-websocket>=0.10.0 (from python-engineio>=4.11.0->python-socketio)\n","  Downloading simple_websocket-1.1.0-py3-none-any.whl.metadata (1.5 kB)\n","Collecting wsproto (from simple-websocket>=0.10.0->python-engineio>=4.11.0->python-socketio)\n","  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n","Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto->simple-websocket>=0.10.0->python-engineio>=4.11.0->python-socketio) (0.14.0)\n","Downloading python_socketio-5.12.1-py3-none-any.whl (76 kB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading bidict-0.23.1-py3-none-any.whl (32 kB)\n","Downloading python_engineio-4.11.2-py3-none-any.whl (59 kB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading simple_websocket-1.1.0-py3-none-any.whl (13 kB)\n","Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n","Installing collected packages: wsproto, bidict, simple-websocket, python-engineio, python-socketio\n","Successfully installed bidict-0.23.1 python-engineio-4.11.2 python-socketio-5.12.1 simple-websocket-1.1.0 wsproto-1.2.0\n","Collecting flask-socketio\n","  Downloading Flask_SocketIO-5.5.1-py3-none-any.whl.metadata (2.6 kB)\n","Requirement already satisfied: Flask>=0.9 in /usr/local/lib/python3.11/dist-packages (from flask-socketio) (3.1.0)\n","Requirement already satisfied: python-socketio>=5.12.0 in /usr/local/lib/python3.11/dist-packages (from flask-socketio) (5.12.1)\n","Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.9->flask-socketio) (3.1.3)\n","Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.9->flask-socketio) (3.1.5)\n","Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.9->flask-socketio) (2.2.0)\n","Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.9->flask-socketio) (8.1.8)\n","Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.9->flask-socketio) (1.9.0)\n","Requirement already satisfied: bidict>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from python-socketio>=5.12.0->flask-socketio) (0.23.1)\n","Requirement already satisfied: python-engineio>=4.11.0 in /usr/local/lib/python3.11/dist-packages (from python-socketio>=5.12.0->flask-socketio) (4.11.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->Flask>=0.9->flask-socketio) (3.0.2)\n","Requirement already satisfied: simple-websocket>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from python-engineio>=4.11.0->python-socketio>=5.12.0->flask-socketio) (1.1.0)\n","Requirement already satisfied: wsproto in /usr/local/lib/python3.11/dist-packages (from simple-websocket>=0.10.0->python-engineio>=4.11.0->python-socketio>=5.12.0->flask-socketio) (1.2.0)\n","Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto->simple-websocket>=0.10.0->python-engineio>=4.11.0->python-socketio>=5.12.0->flask-socketio) (0.14.0)\n","Downloading Flask_SocketIO-5.5.1-py3-none-any.whl (18 kB)\n","Installing collected packages: flask-socketio\n","Successfully installed flask-socketio-5.5.1\n","Collecting pyttsx3\n","  Downloading pyttsx3-2.98-py3-none-any.whl.metadata (3.8 kB)\n","Downloading pyttsx3-2.98-py3-none-any.whl (34 kB)\n","Installing collected packages: pyttsx3\n","Successfully installed pyttsx3-2.98\n","Collecting speechrecognition\n","  Downloading SpeechRecognition-3.14.1-py3-none-any.whl.metadata (31 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from speechrecognition) (4.12.2)\n","Downloading SpeechRecognition-3.14.1-py3-none-any.whl (32.9 MB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: speechrecognition\n","Successfully installed speechrecognition-3.14.1\n","Collecting eventlet\n","  Downloading eventlet-0.39.0-py3-none-any.whl.metadata (5.5 kB)\n","Collecting dnspython>=1.15.0 (from eventlet)\n","  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: greenlet>=1.0 in /usr/local/lib/python3.11/dist-packages (from eventlet) (3.1.1)\n","Downloading eventlet-0.39.0-py3-none-any.whl (363 kB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m363.3/363.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: dnspython, eventlet\n","Successfully installed dnspython-2.7.0 eventlet-0.39.0\n"]}],"source":["!pip install python-socketio\n","!pip install flask-socketio\n","!pip install pyttsx3\n","!pip install speechrecognition\n","!pip install eventlet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VJ2KgKelm2Zi"},"outputs":[],"source":["import socketio\n","import flask_socketio\n","import pyttsx3\n","import speech_recognition as sr\n","import eventlet"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":880},"executionInfo":{"elapsed":24134,"status":"error","timestamp":1737777481724,"user":{"displayName":"Kevin Harry","userId":"14407016036151746140"},"user_tz":-330},"id":"E96lQYWIm5IF","outputId":"df139df6-06e6-42cc-e3bf-ad77b05c14c4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: python-socketio in /usr/local/lib/python3.11/dist-packages (5.12.1)\n","Requirement already satisfied: bidict>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from python-socketio) (0.23.1)\n","Requirement already satisfied: python-engineio>=4.11.0 in /usr/local/lib/python3.11/dist-packages (from python-socketio) (4.11.2)\n","Requirement already satisfied: simple-websocket>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from python-engineio>=4.11.0->python-socketio) (1.1.0)\n","Requirement already satisfied: wsproto in /usr/local/lib/python3.11/dist-packages (from simple-websocket>=0.10.0->python-engineio>=4.11.0->python-socketio) (1.2.0)\n","Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto->simple-websocket>=0.10.0->python-engineio>=4.11.0->python-socketio) (0.14.0)\n","Requirement already satisfied: flask-socketio in /usr/local/lib/python3.11/dist-packages (5.5.1)\n","Requirement already satisfied: Flask>=0.9 in /usr/local/lib/python3.11/dist-packages (from flask-socketio) (3.1.0)\n","Requirement already satisfied: python-socketio>=5.12.0 in /usr/local/lib/python3.11/dist-packages (from flask-socketio) (5.12.1)\n","Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.9->flask-socketio) (3.1.3)\n","Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.9->flask-socketio) (3.1.5)\n","Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.9->flask-socketio) (2.2.0)\n","Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.9->flask-socketio) (8.1.8)\n","Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.9->flask-socketio) (1.9.0)\n","Requirement already satisfied: bidict>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from python-socketio>=5.12.0->flask-socketio) (0.23.1)\n","Requirement already satisfied: python-engineio>=4.11.0 in /usr/local/lib/python3.11/dist-packages (from python-socketio>=5.12.0->flask-socketio) (4.11.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->Flask>=0.9->flask-socketio) (3.0.2)\n","Requirement already satisfied: simple-websocket>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from python-engineio>=4.11.0->python-socketio>=5.12.0->flask-socketio) (1.1.0)\n","Requirement already satisfied: wsproto in /usr/local/lib/python3.11/dist-packages (from simple-websocket>=0.10.0->python-engineio>=4.11.0->python-socketio>=5.12.0->flask-socketio) (1.2.0)\n","Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto->simple-websocket>=0.10.0->python-engineio>=4.11.0->python-socketio>=5.12.0->flask-socketio) (0.14.0)\n","Requirement already satisfied: pyttsx3 in /usr/local/lib/python3.11/dist-packages (2.98)\n","Requirement already satisfied: speechrecognition in /usr/local/lib/python3.11/dist-packages (3.14.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from speechrecognition) (4.12.2)\n","Requirement already satisfied: eventlet in /usr/local/lib/python3.11/dist-packages (0.39.0)\n","Requirement already satisfied: dnspython>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from eventlet) (2.7.0)\n","Requirement already satisfied: greenlet>=1.0 in /usr/local/lib/python3.11/dist-packages (from eventlet) (3.1.1)\n"]},{"ename":"RuntimeError","evalue":"This means you probably do not have eSpeak or eSpeak-ng installed!","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyttsx3/__init__.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(driverName, debug)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0meng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_activeEngines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdriverName\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/weakref.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_commit_removals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: None","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-65d471208f46>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# Initialize the text-to-speech engine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyttsx3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# Create a queue for text-to-speech requests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyttsx3/__init__.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(driverName, debug)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0meng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_activeEngines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdriverName\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0meng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEngine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriverName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0m_activeEngines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdriverName\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meng\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0meng\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyttsx3/engine.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, driverName, debug)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \"\"\"\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproxy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDriverProxy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproxy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdriverName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;31m# initialize other vars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyttsx3/driver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, engine, driverName, debug)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# import driver module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'pyttsx3.drivers.%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdriverName\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;31m# build driver instance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_driver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuildDriver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproxy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyttsx3/drivers/espeak.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvoice\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVoice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_espeak\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfromUtf8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoUtf8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyttsx3/drivers/_espeak.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mload_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"This means you probably do not have eSpeak or eSpeak-ng installed!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: This means you probably do not have eSpeak or eSpeak-ng installed!"]}],"source":["# Install required libraries\n","!pip install python-socketio\n","!pip install flask-socketio\n","!pip install pyttsx3\n","!pip install speechrecognition\n","!pip install eventlet\n","\n","# Import libraries\n","import cv2\n","import numpy as np\n","from keras.models import load_model\n","from PIL import Image, ImageOps\n","from google.colab.patches import cv2_imshow\n","from google.colab import output\n","import base64\n","import io\n","from IPython.display import display, Javascript, Audio\n","import math\n","import time\n","import threading\n","import socketio\n","import queue\n","import pyttsx3\n","import os\n","\n","# Load the drowsy detection model\n","model = load_model(\"/content/keras_model.h5\", compile=False)\n","\n","# Load and process labels correctly\n","with open(\"/content/labels.txt\", \"r\") as f:\n","    class_names = [line.strip().split(' ', 1)[1] for line in f.readlines()]\n","\n","# Path to the alert sound file (converted to .mp3)\n","alert_sound_file = \"/content/alert.mp3\"\n","\n","# Initialize the V2V client\n","sio = socketio.Client()\n","\n","# Initialize the text-to-speech engine\n","engine = pyttsx3.init()\n","\n","# Create a queue for text-to-speech requests\n","speech_queue = queue.Queue()\n","\n","# Function to process text-to-speech requests\n","def speech_worker():\n","    while True:\n","        text = speech_queue.get()\n","        if text is None:\n","            break\n","        engine.say(text)\n","        engine.runAndWait()\n","        speech_queue.task_done()\n","\n","# Start the speech worker thread\n","speech_thread = threading.Thread(target=speech_worker)\n","speech_thread.daemon = True\n","speech_thread.start()\n","\n","# Function to add text to the speech queue\n","def speak(text):\n","    speech_queue.put(text)\n","\n","# Event for when the client connects to the server\n","@sio.event\n","def connect():\n","    print(\"Connected to the V2V server\")\n","    speak(\"Connected to the V2V server\")\n","\n","# Event for when the client disconnects from the server\n","@sio.event\n","def disconnect():\n","    print(\"Disconnected from the V2V server\")\n","    speak(\"Disconnected from the V2V server\")\n","\n","# Event for receiving a response from the server\n","@sio.event\n","def v2v_response(data):\n","    print(f\"Received response: {data}\")\n","    speak(f\"Received response: {data}\")\n","\n","# Connect to the V2V server\n","try:\n","    sio.connect('http://127.0.0.1:5000')\n","except Exception as e:\n","    print(f\"Failed to connect to the V2V server: {e}\")\n","    speak(\"Failed to connect to the V2V server\")\n","\n","# Class to maintain state for drowsy detection\n","class DrowsyDetector:\n","    def __init__(self):\n","        self.drowsy_frame_count = 0\n","        self.non_drowsy_frame_count = 0\n","        self.longest_drowsy_streak = 0\n","        self.longest_non_drowsy_streak = 0\n","        self.total_drowsy_frames = 0\n","        self.total_non_drowsy_frames = 0\n","        self.start_time = time.time()\n","        self.ALERT_THRESHOLD = 5  # Number of continuous drowsy frames to trigger alert sound\n","        self.V2V_THRESHOLD = 10  # Number of continuous drowsy frames to trigger V2V communication\n","\n","    def process_frame(self, frame):\n","        \"\"\"\n","        Process the frame and make a prediction.\n","        \"\"\"\n","        # Resize the frame to 224x224 pixels\n","        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","        image = Image.fromarray(image)\n","        image = ImageOps.fit(image, (224, 224), Image.Resampling.LANCZOS)\n","        image_array = np.asarray(image)\n","\n","        # Normalize the image\n","        normalized_image_array = (image_array.astype(np.float32) / 127.5) - 1\n","\n","        # Create a batch of one image\n","        data = np.expand_dims(normalized_image_array, axis=0)\n","\n","        # Perform prediction\n","        prediction = model.predict(data)\n","        index = np.argmax(prediction)\n","        class_name = class_names[index]\n","        confidence_score = prediction[0][index]\n","\n","        # Format confidence score as a whole number\n","        confidence_score_whole = int(confidence_score * 100)\n","\n","        # Check if the class is \"Drowsy\" (index 0)\n","        if index == 0:  # Directly check the index instead of class name string\n","            self.drowsy_frame_count += 1\n","            self.total_drowsy_frames += 1\n","            if self.drowsy_frame_count > self.longest_drowsy_streak:\n","                self.longest_drowsy_streak = self.drowsy_frame_count\n","            self.non_drowsy_frame_count = 0\n","            print(f\"Drowsy frame detected. Count: {self.drowsy_frame_count}\")\n","        else:\n","            self.non_drowsy_frame_count += 1\n","            self.total_non_drowsy_frames += 1\n","            if self.non_drowsy_frame_count > self.longest_non_drowsy_streak:\n","                self.longest_non_drowsy_streak = self.non_drowsy_frame_count\n","            self.drowsy_frame_count = 0\n","            print(\"Not drowsy. Resetting drowsy counter.\")\n","\n","        # Trigger alert sound if continuous drowsy frames exceed the alert threshold\n","        if self.drowsy_frame_count >= self.ALERT_THRESHOLD and self.drowsy_frame_count < self.V2V_THRESHOLD:\n","            print(\"ALERT: Drowsiness detected! Playing alert sound...\")\n","            display(Audio(alert_sound_file, autoplay=True))  # Play alert sound\n","\n","        # Trigger V2V communication if continuous drowsy frames exceed the V2V threshold\n","        if self.drowsy_frame_count >= self.V2V_THRESHOLD:\n","            print(\"ALERT: Drowsiness detected! Sending alert to V2V server...\")\n","            sio.emit('v2v_message', {'message': \"Driver is not responding. Need assistance!\", 'type': 'emergency'})\n","            self.drowsy_frame_count = 0  # Reset the counter after alert\n","\n","        return class_name, confidence_score_whole\n","\n","    def get_final_stats(self):\n","        \"\"\"\n","        Get final statistics when the webcam is stopped.\n","        \"\"\"\n","        end_time = time.time()\n","        total_time = end_time - self.start_time\n","\n","        stats = {\n","            \"total_drowsy_frames\": self.total_drowsy_frames,\n","            \"total_non_drowsy_frames\": self.total_non_drowsy_frames,\n","            \"longest_drowsy_streak\": self.longest_drowsy_streak,\n","            \"longest_non_drowsy_streak\": self.longest_non_drowsy_streak,\n","            \"total_time\": total_time\n","        }\n","\n","        return stats\n","\n","# Create an instance of the DrowsyDetector class\n","drowsy_detector = DrowsyDetector()\n","\n","# Function to capture an image from the webcam via JavaScript\n","def capture_image():\n","    js = Javascript('''\n","        async function takePhoto() {\n","            const div = document.createElement('div');\n","            const video = document.createElement('video');\n","            const canvas = document.createElement('canvas');\n","            const button = document.createElement('button');\n","            button.textContent = 'Stop';\n","\n","            div.appendChild(video);\n","            div.appendChild(button);\n","            document.body.appendChild(div);\n","\n","            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n","            video.srcObject = stream;\n","            await video.play();\n","\n","            return new Promise((resolve) => {\n","                button.onclick = () => {\n","                    stream.getTracks().forEach(track => track.stop());\n","                    div.remove();\n","                    resolve(null);\n","                };\n","\n","                setInterval(async () => {\n","                    if (!video.srcObject.active) {\n","                        resolve(null);\n","                        return;\n","                    }\n","                    canvas.width = video.videoWidth;\n","                    canvas.height = video.videoHeight;\n","                    canvas.getContext('2d').drawImage(video, 0, 0);\n","                    const data = canvas.toDataURL('image/jpeg').split(',')[1];\n","                    google.colab.kernel.invokeFunction('notebook.captureFrameCallback', [data], {});\n","                }, 1000); // Capture every second\n","            });\n","        }\n","        takePhoto();\n","    ''')\n","    display(js)\n","\n","# Callback to process the captured image\n","def capture_frame_callback(image_data):\n","    if image_data is None:\n","        print(\"Stopping webcam...\")\n","        stats = drowsy_detector.get_final_stats()\n","        print(\"\\nFinal Statistics:\")\n","        print(f\"Total Drowsy Frames: {stats['total_drowsy_frames']}\")\n","        print(f\"Total Non-Drowsy Frames: {stats['total_non_drowsy_frames']}\")\n","        print(f\"Longest Drowsy Streak: {stats['longest_drowsy_streak']} frames\")\n","        print(f\"Longest Non-Drowsy Streak: {stats['longest_non_drowsy_streak']} frames\")\n","        print(f\"Total Time: {stats['total_time']:.2f} seconds\")\n","        return\n","\n","    try:\n","        # Decode the image data\n","        image_bytes = base64.b64decode(image_data)\n","        frame = Image.open(io.BytesIO(image_bytes))\n","        frame = cv2.cvtColor(np.array(frame), cv2.COLOR_RGB2BGR)\n","\n","        # Process the frame\n","        class_name, confidence_score_whole = drowsy_detector.process_frame(frame)\n","\n","        # Add drowsiness details to the frame\n","        text = f\"Class: {class_name}\\nConfidence: {confidence_score_whole}%\\nDrowsy Frames: {drowsy_detector.drowsy_frame_count}\\nNon-Drowsy Frames: {drowsy_detector.non_drowsy_frame_count}\"\n","\n","        # Position the text on the right side of the frame\n","        text_x = frame.shape[1] - 300\n","        text_y = 50\n","        font = cv2.FONT_HERSHEY_SIMPLEX\n","        font_scale = 0.8\n","        font_color = (0, 255, 0)\n","        font_thickness = 2\n","\n","        # Split the text into lines\n","        lines = text.split('\\n')\n","        for i, line in enumerate(lines):\n","            y = text_y + i * 30\n","            cv2.putText(frame, line, (text_x, y), font, font_scale, font_color, font_thickness, cv2.LINE_AA)\n","\n","        # Display the result\n","        cv2_imshow(frame)\n","    except Exception as e:\n","        print(f\"Error processing frame: {e}\")\n","\n","# Register callback function\n","output.register_callback('notebook.captureFrameCallback', capture_frame_callback)\n","\n","# Start capturing\n","capture_image()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14054,"status":"ok","timestamp":1737865297639,"user":{"displayName":"Kevin Harry","userId":"14407016036151746140"},"user_tz":-330},"id":"HUYJmp95nJN2","outputId":"fafc9615-2da6-4e31-f743-b7175a46abc7"},"outputs":[{"name":"stdout","output_type":"stream","text":["\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n","\r0% [Connecting to archive.ubuntu.com (185.125.190.81)] [Connecting to security.\r0% [Connecting to archive.ubuntu.com (185.125.190.81)] [Connecting to security.\r                                                                               \rGet:2 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n","\r0% [Waiting for headers] [2 InRelease 14.2 kB/129 kB 11%] [Waiting for headers]\r                                                                               \rGet:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n","\r0% [Waiting for headers] [2 InRelease 14.2 kB/129 kB 11%] [Waiting for headers]\r                                                                               \rHit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n","Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n","Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,285 kB]\n","Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Get:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n","Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,648 kB]\n","Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,627 kB]\n","Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,861 kB]\n","Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,520 kB]\n","Fetched 17.3 MB in 2s (7,592 kB/s)\n","Reading package lists... Done\n","W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following additional packages will be installed:\n","  espeak-data libespeak1 libportaudio2 libsonic0\n","The following NEW packages will be installed:\n","  espeak espeak-data libespeak1 libportaudio2 libsonic0\n","0 upgraded, 5 newly installed, 0 to remove and 52 not upgraded.\n","Need to get 1,382 kB of archives.\n","After this operation, 3,178 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libportaudio2 amd64 19.6.0-1.1 [65.3 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsonic0 amd64 0.2.0-11build1 [10.3 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 espeak-data amd64 1.48.15+dfsg-3 [1,085 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libespeak1 amd64 1.48.15+dfsg-3 [156 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 espeak amd64 1.48.15+dfsg-3 [64.2 kB]\n","Fetched 1,382 kB in 1s (1,469 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 5.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package libportaudio2:amd64.\n","(Reading database ... 124574 files and directories currently installed.)\n","Preparing to unpack .../libportaudio2_19.6.0-1.1_amd64.deb ...\n","Unpacking libportaudio2:amd64 (19.6.0-1.1) ...\n","Selecting previously unselected package libsonic0:amd64.\n","Preparing to unpack .../libsonic0_0.2.0-11build1_amd64.deb ...\n","Unpacking libsonic0:amd64 (0.2.0-11build1) ...\n","Selecting previously unselected package espeak-data:amd64.\n","Preparing to unpack .../espeak-data_1.48.15+dfsg-3_amd64.deb ...\n","Unpacking espeak-data:amd64 (1.48.15+dfsg-3) ...\n","Selecting previously unselected package libespeak1:amd64.\n","Preparing to unpack .../libespeak1_1.48.15+dfsg-3_amd64.deb ...\n","Unpacking libespeak1:amd64 (1.48.15+dfsg-3) ...\n","Selecting previously unselected package espeak.\n","Preparing to unpack .../espeak_1.48.15+dfsg-3_amd64.deb ...\n","Unpacking espeak (1.48.15+dfsg-3) ...\n","Setting up libportaudio2:amd64 (19.6.0-1.1) ...\n","Setting up libsonic0:amd64 (0.2.0-11build1) ...\n","Setting up espeak-data:amd64 (1.48.15+dfsg-3) ...\n","Setting up libespeak1:amd64 (1.48.15+dfsg-3) ...\n","Setting up espeak (1.48.15+dfsg-3) ...\n","Processing triggers for man-db (2.10.2-1) ...\n","Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n","\n"]}],"source":["!sudo apt-get update\n","!sudo apt-get install espeak"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":493,"status":"ok","timestamp":1737865304943,"user":{"displayName":"Kevin Harry","userId":"14407016036151746140"},"user_tz":-330},"id":"S0bH-wHvnQjw","outputId":"925961bb-525e-4684-c9d3-e3657283faf1"},"outputs":[{"name":"stdout","output_type":"stream","text":["eSpeak text-to-speech: 1.48.15  16.Apr.15  Data at: /usr/lib/x86_64-linux-gnu/espeak-data\n"]}],"source":["!espeak --version"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p_0I1E2UnSrq"},"outputs":[],"source":["import pyttsx3\n","\n","# Initialize the text-to-speech engine\n","engine = pyttsx3.init()\n","\n","# Test the engine\n","engine.say(\"Hello, this is a test.\")\n","engine.runAndWait()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5332,"status":"ok","timestamp":1737777589487,"user":{"displayName":"Kevin Harry","userId":"14407016036151746140"},"user_tz":-330},"id":"Hy-6Ln3RnVhu","outputId":"62df96fa-95fe-488e-bec4-5795f127432a"},"outputs":[{"name":"stdout","output_type":"stream","text":["V2V Server and Traffic Police Server are running in the background.\n"]}],"source":["import subprocess\n","import time\n","\n","# Start the V2V server\n","v2v_server_process = subprocess.Popen([\"python\", \"v2v_server.py\"])\n","\n","# Start the Traffic Police server\n","traffic_police_server_process = subprocess.Popen([\"python\", \"traffic_police_server.py\"])\n","\n","# Wait for the servers to start\n","time.sleep(5)\n","\n","print(\"V2V Server and Traffic Police Server are running in the background.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":21463,"status":"error","timestamp":1737786268206,"user":{"displayName":"Kevin Harry","userId":"14407016036151746140"},"user_tz":-330},"id":"UGSg4tk4nYJt","outputId":"80d1b017-0ee4-4265-a5c1-e543263cb5c1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: python-socketio in /usr/local/lib/python3.11/dist-packages (5.12.1)\n","Requirement already satisfied: bidict>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from python-socketio) (0.23.1)\n","Requirement already satisfied: python-engineio>=4.11.0 in /usr/local/lib/python3.11/dist-packages (from python-socketio) (4.11.2)\n","Requirement already satisfied: simple-websocket>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from python-engineio>=4.11.0->python-socketio) (1.1.0)\n","Requirement already satisfied: wsproto in /usr/local/lib/python3.11/dist-packages (from simple-websocket>=0.10.0->python-engineio>=4.11.0->python-socketio) (1.2.0)\n","Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto->simple-websocket>=0.10.0->python-engineio>=4.11.0->python-socketio) (0.14.0)\n","Requirement already satisfied: flask-socketio in /usr/local/lib/python3.11/dist-packages (5.5.1)\n","Requirement already satisfied: Flask>=0.9 in /usr/local/lib/python3.11/dist-packages (from flask-socketio) (3.1.0)\n","Requirement already satisfied: python-socketio>=5.12.0 in /usr/local/lib/python3.11/dist-packages (from flask-socketio) (5.12.1)\n","Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.9->flask-socketio) (3.1.3)\n","Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.9->flask-socketio) (3.1.5)\n","Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.9->flask-socketio) (2.2.0)\n","Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.9->flask-socketio) (8.1.8)\n","Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.9->flask-socketio) (1.9.0)\n","Requirement already satisfied: bidict>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from python-socketio>=5.12.0->flask-socketio) (0.23.1)\n","Requirement already satisfied: python-engineio>=4.11.0 in /usr/local/lib/python3.11/dist-packages (from python-socketio>=5.12.0->flask-socketio) (4.11.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->Flask>=0.9->flask-socketio) (3.0.2)\n","Requirement already satisfied: simple-websocket>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from python-engineio>=4.11.0->python-socketio>=5.12.0->flask-socketio) (1.1.0)\n","Requirement already satisfied: wsproto in /usr/local/lib/python3.11/dist-packages (from simple-websocket>=0.10.0->python-engineio>=4.11.0->python-socketio>=5.12.0->flask-socketio) (1.2.0)\n","Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto->simple-websocket>=0.10.0->python-engineio>=4.11.0->python-socketio>=5.12.0->flask-socketio) (0.14.0)\n","Requirement already satisfied: pyttsx3 in /usr/local/lib/python3.11/dist-packages (2.98)\n","Requirement already satisfied: speechrecognition in /usr/local/lib/python3.11/dist-packages (3.14.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from speechrecognition) (4.12.2)\n","Requirement already satisfied: eventlet in /usr/local/lib/python3.11/dist-packages (0.39.0)\n","Requirement already satisfied: dnspython>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from eventlet) (2.7.0)\n","Requirement already satisfied: greenlet>=1.0 in /usr/local/lib/python3.11/dist-packages (from eventlet) (3.1.1)\n","Hit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n","Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n","Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n","Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n","Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n","Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n","Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Fetched 6,555 B in 1s (5,275 B/s)\n","Reading package lists... Done\n","W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","espeak is already the newest version (1.48.15+dfsg-3).\n","0 upgraded, 0 newly installed, 0 to remove and 52 not upgraded.\n"]},{"ename":"FileNotFoundError","evalue":"[Errno 2] Unable to synchronously open file (unable to open file: name = '/content/keras_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-d0e8427cda6d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Load the drowsy detection model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/keras_model.h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Load and process labels correctly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    192\u001b[0m         )\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         return legacy_h5_format.load_model_from_hdf5(\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/legacy_h5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0mopened_new_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    559\u001b[0m                                  \u001b[0mfs_persist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_persist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m                                  fs_page_size=fs_page_size)\n\u001b[0;32m--> 561\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = '/content/keras_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"]}],"source":["# Install required libraries\n","!pip install python-socketio\n","!pip install flask-socketio\n","!pip install pyttsx3\n","!pip install speechrecognition\n","!pip install eventlet\n","\n","# Install eSpeak\n","!sudo apt-get update\n","!sudo apt-get install espeak\n","\n","# Import libraries\n","import cv2\n","import numpy as np\n","from keras.models import load_model\n","from PIL import Image, ImageOps\n","from google.colab.patches import cv2_imshow\n","from google.colab import output\n","import base64\n","import io\n","from IPython.display import display, Javascript, Audio\n","import math\n","import time\n","import threading\n","import socketio\n","import queue\n","import pyttsx3\n","import os\n","\n","# Load the drowsy detection model\n","model = load_model(\"/content/keras_model.h5\", compile=False)\n","\n","# Load and process labels correctly\n","with open(\"/content/labels.txt\", \"r\") as f:\n","    class_names = [line.strip().split(' ', 1)[1] for line in f.readlines()]\n","\n","# Path to the alert sound file (converted to .mp3)\n","alert_sound_file = \"/content/alert.mp3\"\n","\n","# Initialize the V2V client\n","sio = socketio.Client()\n","\n","# Initialize the text-to-speech engine\n","engine = pyttsx3.init()\n","\n","# Create a queue for text-to-speech requests\n","speech_queue = queue.Queue()\n","\n","# Function to process text-to-speech requests\n","def speech_worker():\n","    while True:\n","        text = speech_queue.get()\n","        if text is None:\n","            break\n","        engine.say(text)\n","        engine.runAndWait()\n","        speech_queue.task_done()\n","\n","# Start the speech worker thread\n","speech_thread = threading.Thread(target=speech_worker)\n","speech_thread.daemon = True\n","speech_thread.start()\n","\n","# Function to add text to the speech queue\n","def speak(text):\n","    speech_queue.put(text)\n","\n","# Event for when the client connects to the server\n","@sio.event\n","def connect():\n","    print(\"Connected to the V2V server\")\n","    speak(\"Connected to the V2V server\")\n","\n","# Event for when the client disconnects from the server\n","@sio.event\n","def disconnect():\n","    print(\"Disconnected from the V2V server\")\n","    speak(\"Disconnected from the V2V server\")\n","\n","# Event for receiving a response from the server\n","@sio.event\n","def v2v_response(data):\n","    print(f\"Received response: {data}\")\n","    speak(f\"Received response: {data}\")\n","\n","# Connect to the V2V server\n","try:\n","    sio.connect('http://127.0.0.1:5000')\n","except Exception as e:\n","    print(f\"Failed to connect to the V2V server: {e}\")\n","    speak(\"Failed to connect to the V2V server\")\n","\n","# Class to maintain state for drowsy detection\n","class DrowsyDetector:\n","    def __init__(self):\n","        self.drowsy_frame_count = 0\n","        self.non_drowsy_frame_count = 0\n","        self.longest_drowsy_streak = 0\n","        self.longest_non_drowsy_streak = 0\n","        self.total_drowsy_frames = 0\n","        self.total_non_drowsy_frames = 0\n","        self.start_time = time.time()\n","        self.ALERT_THRESHOLD = 5  # Number of continuous drowsy frames to trigger alert sound\n","        self.V2V_THRESHOLD = 10  # Number of continuous drowsy frames to trigger V2V communication\n","\n","    def process_frame(self, frame):\n","        \"\"\"\n","        Process the frame and make a prediction.\n","        \"\"\"\n","        # Resize the frame to 224x224 pixels\n","        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","        image = Image.fromarray(image)\n","        image = ImageOps.fit(image, (224, 224), Image.Resampling.LANCZOS)\n","        image_array = np.asarray(image)\n","\n","        # Normalize the image\n","        normalized_image_array = (image_array.astype(np.float32) / 127.5) - 1\n","\n","        # Create a batch of one image\n","        data = np.expand_dims(normalized_image_array, axis=0)\n","\n","        # Perform prediction\n","        prediction = model.predict(data)\n","        index = np.argmax(prediction)\n","        class_name = class_names[index]\n","        confidence_score = prediction[0][index]\n","\n","        # Format confidence score as a whole number\n","        confidence_score_whole = int(confidence_score * 100)\n","\n","        # Check if the class is \"Drowsy\" (index 0)\n","        if index == 0:  # Directly check the index instead of class name string\n","            self.drowsy_frame_count += 1\n","            self.total_drowsy_frames += 1\n","            if self.drowsy_frame_count > self.longest_drowsy_streak:\n","                self.longest_drowsy_streak = self.drowsy_frame_count\n","            self.non_drowsy_frame_count = 0\n","            print(f\"Drowsy frame detected. Count: {self.drowsy_frame_count}\")\n","        else:\n","            self.non_drowsy_frame_count += 1\n","            self.total_non_drowsy_frames += 1\n","            if self.non_drowsy_frame_count > self.longest_non_drowsy_streak:\n","                self.longest_non_drowsy_streak = self.non_drowsy_frame_count\n","            self.drowsy_frame_count = 0\n","            print(\"Not drowsy. Resetting drowsy counter.\")\n","\n","        # Trigger alert sound if continuous drowsy frames exceed the alert threshold\n","        if self.drowsy_frame_count >= self.ALERT_THRESHOLD and self.drowsy_frame_count < self.V2V_THRESHOLD:\n","            print(\"ALERT: Drowsiness detected! Playing alert sound...\")\n","            display(Audio(alert_sound_file, autoplay=True))  # Play alert sound\n","\n","        # Trigger V2V communication if continuous drowsy frames exceed the V2V threshold\n","        if self.drowsy_frame_count >= self.V2V_THRESHOLD:\n","            print(\"ALERT: Drowsiness detected! Sending alert to V2V server...\")\n","            sio.emit('v2v_message', {'message': \"Driver is not responding. Need assistance!\", 'type': 'emergency'})\n","            self.drowsy_frame_count = 0  # Reset the counter after alert\n","\n","        return class_name, confidence_score_whole\n","\n","    def get_final_stats(self):\n","        \"\"\"\n","        Get final statistics when the webcam is stopped.\n","        \"\"\"\n","        end_time = time.time()\n","        total_time = end_time - self.start_time\n","\n","        stats = {\n","            \"total_drowsy_frames\": self.total_drowsy_frames,\n","            \"total_non_drowsy_frames\": self.total_non_drowsy_frames,\n","            \"longest_drowsy_streak\": self.longest_drowsy_streak,\n","            \"longest_non_drowsy_streak\": self.longest_non_drowsy_streak,\n","            \"total_time\": total_time\n","        }\n","\n","        return stats\n","\n","# Create an instance of the DrowsyDetector class\n","drowsy_detector = DrowsyDetector()\n","\n","# Function to capture an image from the webcam via JavaScript\n","def capture_image():\n","    js = Javascript('''\n","        async function takePhoto() {\n","            const div = document.createElement('div');\n","            const video = document.createElement('video');\n","            const canvas = document.createElement('canvas');\n","            const button = document.createElement('button');\n","            button.textContent = 'Stop';\n","\n","            div.appendChild(video);\n","            div.appendChild(button);\n","            document.body.appendChild(div);\n","\n","            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n","            video.srcObject = stream;\n","            await video.play();\n","\n","            return new Promise((resolve) => {\n","                button.onclick = () => {\n","                    stream.getTracks().forEach(track => track.stop());\n","                    div.remove();\n","                    resolve(null);\n","                };\n","\n","                setInterval(async () => {\n","                    if (!video.srcObject.active) {\n","                        resolve(null);\n","                        return;\n","                    }\n","                    canvas.width = video.videoWidth;\n","                    canvas.height = video.videoHeight;\n","                    canvas.getContext('2d').drawImage(video, 0, 0);\n","                    const data = canvas.toDataURL('image/jpeg').split(',')[1];\n","                    google.colab.kernel.invokeFunction('notebook.captureFrameCallback', [data], {});\n","                }, 1000); // Capture every second\n","            });\n","        }\n","        takePhoto();\n","    ''')\n","    display(js)\n","\n","# Callback to process the captured image\n","def capture_frame_callback(image_data):\n","    if image_data is None:\n","        print(\"Stopping webcam...\")\n","        stats = drowsy_detector.get_final_stats()\n","        print(\"\\nFinal Statistics:\")\n","        print(f\"Total Drowsy Frames: {stats['total_drowsy_frames']}\")\n","        print(f\"Total Non-Drowsy Frames: {stats['total_non_drowsy_frames']}\")\n","        print(f\"Longest Drowsy Streak: {stats['longest_drowsy_streak']} frames\")\n","        print(f\"Longest Non-Drowsy Streak: {stats['longest_non_drowsy_streak']} frames\")\n","        print(f\"Total Time: {stats['total_time']:.2f} seconds\")\n","        return\n","\n","    try:\n","        # Decode the image data\n","        image_bytes = base64.b64decode(image_data)\n","        frame = Image.open(io.BytesIO(image_bytes))\n","        frame = cv2.cvtColor(np.array(frame), cv2.COLOR_RGB2BGR)\n","\n","        # Process the frame\n","        class_name, confidence_score_whole = drowsy_detector.process_frame(frame)\n","\n","        # Add drowsiness details to the frame\n","        text = f\"Class: {class_name}\\nConfidence: {confidence_score_whole}%\\nDrowsy Frames: {drowsy_detector.drowsy_frame_count}\\nNon-Drowsy Frames: {drowsy_detector.non_drowsy_frame_count}\"\n","\n","        # Position the text on the right side of the frame\n","        text_x = frame.shape[1] - 300\n","        text_y = 50\n","        font = cv2.FONT_HERSHEY_SIMPLEX\n","        font_scale = 0.8\n","        font_color = (0, 255, 0)\n","        font_thickness = 2\n","\n","        # Split the text into lines\n","        lines = text.split('\\n')\n","        for i, line in enumerate(lines):\n","            y = text_y + i * 30\n","            cv2.putText(frame, line, (text_x, y), font, font_scale, font_color, font_thickness, cv2.LINE_AA)\n","\n","        # Display the result\n","        cv2_imshow(frame)\n","    except Exception as e:\n","        print(f\"Error processing frame: {e}\")\n","\n","# Register callback function\n","output.register_callback('notebook.captureFrameCallback', capture_frame_callback)\n","\n","# Start capturing\n","capture_image()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5589,"status":"ok","timestamp":1737865327430,"user":{"displayName":"Kevin Harry","userId":"14407016036151746140"},"user_tz":-330},"id":"SV7rhQpzn6rY","outputId":"6a250abc-27f1-4639-953f-558c42fc7282"},"outputs":[{"name":"stdout","output_type":"stream","text":["V2V Server and Traffic Police Server are running in the background.\n"]}],"source":["import subprocess\n","import time\n","\n","# Start the V2V server\n","v2v_server_process = subprocess.Popen([\"python\", \"v2v_server.py\"])\n","\n","# Start the Traffic Police server\n","traffic_police_server_process = subprocess.Popen([\"python\", \"traffic_police_server.py\"])\n","\n","# Wait for the servers to start\n","time.sleep(5)\n","\n","print(\"V2V Server and Traffic Police Server are running in the background.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"xwDg-jBJonEw","outputId":"45f1aeac-ec05-4de0-b422-7c7492bd0324"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: python-socketio in /usr/local/lib/python3.11/dist-packages (5.12.1)\n","Requirement already satisfied: bidict>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from python-socketio) (0.23.1)\n","Requirement already satisfied: python-engineio>=4.11.0 in /usr/local/lib/python3.11/dist-packages (from python-socketio) (4.11.2)\n","Requirement already satisfied: simple-websocket>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from python-engineio>=4.11.0->python-socketio) (1.1.0)\n","Requirement already satisfied: wsproto in /usr/local/lib/python3.11/dist-packages (from simple-websocket>=0.10.0->python-engineio>=4.11.0->python-socketio) (1.2.0)\n","Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto->simple-websocket>=0.10.0->python-engineio>=4.11.0->python-socketio) (0.14.0)\n","Requirement already satisfied: flask-socketio in /usr/local/lib/python3.11/dist-packages (5.5.1)\n","Requirement already satisfied: Flask>=0.9 in /usr/local/lib/python3.11/dist-packages (from flask-socketio) (3.1.0)\n","Requirement already satisfied: python-socketio>=5.12.0 in /usr/local/lib/python3.11/dist-packages (from flask-socketio) (5.12.1)\n","Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.9->flask-socketio) (3.1.3)\n","Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.9->flask-socketio) (3.1.5)\n","Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.9->flask-socketio) (2.2.0)\n","Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.9->flask-socketio) (8.1.8)\n","Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.9->flask-socketio) (1.9.0)\n","Requirement already satisfied: bidict>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from python-socketio>=5.12.0->flask-socketio) (0.23.1)\n","Requirement already satisfied: python-engineio>=4.11.0 in /usr/local/lib/python3.11/dist-packages (from python-socketio>=5.12.0->flask-socketio) (4.11.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->Flask>=0.9->flask-socketio) (3.0.2)\n","Requirement already satisfied: simple-websocket>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from python-engineio>=4.11.0->python-socketio>=5.12.0->flask-socketio) (1.1.0)\n","Requirement already satisfied: wsproto in /usr/local/lib/python3.11/dist-packages (from simple-websocket>=0.10.0->python-engineio>=4.11.0->python-socketio>=5.12.0->flask-socketio) (1.2.0)\n","Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto->simple-websocket>=0.10.0->python-engineio>=4.11.0->python-socketio>=5.12.0->flask-socketio) (0.14.0)\n","Requirement already satisfied: pyttsx3 in /usr/local/lib/python3.11/dist-packages (2.98)\n","Requirement already satisfied: speechrecognition in /usr/local/lib/python3.11/dist-packages (3.14.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from speechrecognition) (4.12.2)\n","Requirement already satisfied: eventlet in /usr/local/lib/python3.11/dist-packages (0.39.0)\n","Requirement already satisfied: dnspython>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from eventlet) (2.7.0)\n","Requirement already satisfied: greenlet>=1.0 in /usr/local/lib/python3.11/dist-packages (from eventlet) (3.1.1)\n","Get:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n","Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n","Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n","Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Hit:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n","Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n","Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n","Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Fetched 129 kB in 2s (71.8 kB/s)\n","Reading package lists... Done\n","W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","espeak is already the newest version (1.48.15+dfsg-3).\n","0 upgraded, 0 newly installed, 0 to remove and 52 not upgraded.\n","Failed to connect to the V2V server: HTTPConnectionPool(host='127.0.0.1', port=5000): Max retries exceeded with url: /socket.io/?transport=polling&EIO=4&t=1737869151.9575505 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7c98f5e23d50>: Failed to establish a new connection: [Errno 111] Connection refused'))\n"]},{"data":{"application/javascript":["\n","        async function takePhoto() {\n","            const div = document.createElement('div');\n","            const video = document.createElement('video');\n","            const canvas = document.createElement('canvas');\n","            const button = document.createElement('button');\n","            button.textContent = 'Stop';\n","\n","            div.appendChild(video);\n","            div.appendChild(button);\n","            document.body.appendChild(div);\n","\n","            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n","            video.srcObject = stream;\n","            await video.play();\n","\n","            return new Promise((resolve) => {\n","                button.onclick = () => {\n","                    stream.getTracks().forEach(track => track.stop());\n","                    div.remove();\n","                    resolve(null);\n","                };\n","\n","                setInterval(async () => {\n","                    if (!video.srcObject.active) {\n","                        resolve(null);\n","                        return;\n","                    }\n","                    canvas.width = video.videoWidth;\n","                    canvas.height = video.videoHeight;\n","                    canvas.getContext('2d').drawImage(video, 0, 0);\n","                    const data = canvas.toDataURL('image/jpeg').split(',')[1];\n","                    google.colab.kernel.invokeFunction('notebook.captureFrameCallback', [data], {});\n","                }, 1000); // Capture every second\n","            });\n","        }\n","        takePhoto();\n","    "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"}],"source":["# Install required libraries\n","!pip install python-socketio\n","!pip install flask-socketio\n","!pip install pyttsx3\n","!pip install speechrecognition\n","!pip install eventlet\n","\n","# Install eSpeak\n","!sudo apt-get update\n","!sudo apt-get install espeak\n","\n","# Import libraries\n","import cv2\n","import numpy as np\n","from keras.models import load_model\n","from PIL import Image, ImageOps\n","from google.colab.patches import cv2_imshow\n","from google.colab import output\n","import base64\n","import io\n","from IPython.display import display, Javascript, Audio\n","import math\n","import time\n","import threading\n","import socketio\n","import queue\n","import pyttsx3\n","import os\n","\n","# Load the drowsy detection model\n","model = load_model(\"/content/keras_model.h5\", compile=False)\n","\n","# Load and process labels correctly\n","with open(\"/content/labels.txt\", \"r\") as f:\n","    class_names = [line.strip().split(' ', 1)[1] for line in f.readlines()]\n","\n","# Path to the alert sound file (converted to .mp3)\n","alert_sound_file = \"/content/alert.mp3\"\n","\n","# Initialize the V2V client\n","sio = socketio.Client()\n","\n","# Initialize the text-to-speech engine\n","engine = pyttsx3.init()\n","\n","# Create a queue for text-to-speech requests\n","speech_queue = queue.Queue()\n","\n","# Function to process text-to-speech requests\n","def speech_worker():\n","    while True:\n","        text = speech_queue.get()\n","        if text is None:\n","            break\n","        engine.say(text)\n","        engine.runAndWait()\n","        speech_queue.task_done()\n","\n","# Start the speech worker thread\n","speech_thread = threading.Thread(target=speech_worker)\n","speech_thread.daemon = True\n","speech_thread.start()\n","\n","# Function to add text to the speech queue\n","def speak(text):\n","    speech_queue.put(text)\n","\n","# Event for when the client connects to the server\n","@sio.event\n","def connect():\n","    print(\"Connected to the V2V server\")\n","    speak(\"Connected to the V2V server\")\n","\n","# Event for when the client disconnects from the server\n","@sio.event\n","def disconnect():\n","    print(\"Disconnected from the V2V server\")\n","    speak(\"Disconnected from the V2V server\")\n","\n","# Event for receiving a response from the server\n","@sio.event\n","def v2v_response(data):\n","    print(f\"Received response: {data}\")\n","    speak(f\"Received response: {data}\")\n","\n","# Connect to the V2V server\n","try:\n","    sio.connect('http://127.0.0.1:5000')\n","except Exception as e:\n","    print(f\"Failed to connect to the V2V server: {e}\")\n","    speak(\"Failed to connect to the V2V server\")\n","\n","# Class to maintain state for drowsy detection\n","class DrowsyDetector:\n","    def __init__(self):\n","        self.drowsy_frame_count = 0\n","        self.non_drowsy_frame_count = 0\n","        self.longest_drowsy_streak = 0\n","        self.longest_non_drowsy_streak = 0\n","        self.total_drowsy_frames = 0\n","        self.total_non_drowsy_frames = 0\n","        self.start_time = time.time()\n","        self.ALERT_THRESHOLD = 5  # Number of continuous drowsy frames to trigger alert sound\n","        self.V2V_THRESHOLD = 10  # Number of continuous drowsy frames to trigger V2V communication\n","\n","    def process_frame(self, frame):\n","        \"\"\"\n","        Process the frame and make a prediction.\n","        \"\"\"\n","        # Resize the frame to 224x224 pixels\n","        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","        image = Image.fromarray(image)\n","        image = ImageOps.fit(image, (224, 224), Image.Resampling.LANCZOS)\n","        image_array = np.asarray(image)\n","\n","        # Normalize the image\n","        normalized_image_array = (image_array.astype(np.float32) / 127.5) - 1\n","\n","        # Create a batch of one image\n","        data = np.expand_dims(normalized_image_array, axis=0)\n","\n","        # Perform prediction\n","        prediction = model.predict(data)\n","        index = np.argmax(prediction)\n","        class_name = class_names[index]\n","        confidence_score = prediction[0][index]\n","\n","        # Format confidence score as a whole number\n","        confidence_score_whole = int(confidence_score * 100)\n","\n","        # Check if the class is \"Drowsy\" (index 0)\n","        if index == 0:  # Directly check the index instead of class name string\n","            self.drowsy_frame_count += 1\n","            self.total_drowsy_frames += 1\n","            if self.drowsy_frame_count > self.longest_drowsy_streak:\n","                self.longest_drowsy_streak = self.drowsy_frame_count\n","            self.non_drowsy_frame_count = 0\n","            print(f\"Drowsy frame detected. Count: {self.drowsy_frame_count}\")\n","\n","            # Trigger alert sound if continuous drowsy frames exceed the alert threshold\n","            if self.drowsy_frame_count == self.ALERT_THRESHOLD:\n","                print(\"ALERT: Drowsiness detected! Playing alert sound...\")\n","                display(Audio(alert_sound_file, autoplay=True))  # Play alert sound\n","\n","            # Trigger V2V communication if continuous drowsy frames exceed the V2V threshold\n","            if self.drowsy_frame_count == self.V2V_THRESHOLD:\n","                print(\"ALERT: Drowsiness detected! Sending alert to V2V server and Traffic Police server...\")\n","                sio.emit('v2v_message', {'message': \"Driver is not responding. Need assistance!\", 'type': 'emergency'})\n","                sio.emit('traffic_police_message', {'message': \"Driver is not responding. Need assistance!\", 'type': 'emergency'})\n","                self.drowsy_frame_count = 0  # Reset the counter after alert\n","        else:\n","            self.non_drowsy_frame_count += 1\n","            self.total_non_drowsy_frames += 1\n","            if self.non_drowsy_frame_count > self.longest_non_drowsy_streak:\n","                self.longest_non_drowsy_streak = self.non_drowsy_frame_count\n","            self.drowsy_frame_count = 0\n","            print(\"Not drowsy. Resetting drowsy counter.\")\n","\n","        return class_name, confidence_score_whole\n","\n","    def get_final_stats(self):\n","        \"\"\"\n","        Get final statistics when the webcam is stopped.\n","        \"\"\"\n","        end_time = time.time()\n","        total_time = end_time - self.start_time\n","\n","        stats = {\n","            \"total_drowsy_frames\": self.total_drowsy_frames,\n","            \"total_non_drowsy_frames\": self.total_non_drowsy_frames,\n","            \"longest_drowsy_streak\": self.longest_drowsy_streak,\n","            \"longest_non_drowsy_streak\": self.longest_non_drowsy_streak,\n","            \"total_time\": total_time\n","        }\n","\n","        return stats\n","\n","# Create an instance of the DrowsyDetector class\n","drowsy_detector = DrowsyDetector()\n","\n","# Function to capture an image from the webcam via JavaScript\n","def capture_image():\n","    js = Javascript('''\n","        async function takePhoto() {\n","            const div = document.createElement('div');\n","            const video = document.createElement('video');\n","            const canvas = document.createElement('canvas');\n","            const button = document.createElement('button');\n","            button.textContent = 'Stop';\n","\n","            div.appendChild(video);\n","            div.appendChild(button);\n","            document.body.appendChild(div);\n","\n","            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n","            video.srcObject = stream;\n","            await video.play();\n","\n","            return new Promise((resolve) => {\n","                button.onclick = () => {\n","                    stream.getTracks().forEach(track => track.stop());\n","                    div.remove();\n","                    resolve(null);\n","                };\n","\n","                setInterval(async () => {\n","                    if (!video.srcObject.active) {\n","                        resolve(null);\n","                        return;\n","                    }\n","                    canvas.width = video.videoWidth;\n","                    canvas.height = video.videoHeight;\n","                    canvas.getContext('2d').drawImage(video, 0, 0);\n","                    const data = canvas.toDataURL('image/jpeg').split(',')[1];\n","                    google.colab.kernel.invokeFunction('notebook.captureFrameCallback', [data], {});\n","                }, 1000); // Capture every second\n","            });\n","        }\n","        takePhoto();\n","    ''')\n","    display(js)\n","\n","# Callback to process the captured image\n","def capture_frame_callback(image_data):\n","    if image_data is None:\n","        print(\"Stopping webcam...\")\n","        stats = drowsy_detector.get_final_stats()\n","        print(\"\\nFinal Statistics:\")\n","        print(f\"Total Drowsy Frames: {stats['total_drowsy_frames']}\")\n","        print(f\"Total Non-Drowsy Frames: {stats['total_non_drowsy_frames']}\")\n","        print(f\"Longest Drowsy Streak: {stats['longest_drowsy_streak']} frames\")\n","        print(f\"Longest Non-Drowsy Streak: {stats['longest_non_drowsy_streak']} frames\")\n","        print(f\"Total Time: {stats['total_time']:.2f} seconds\")\n","        return\n","\n","    try:\n","        # Decode the image data\n","        image_bytes = base64.b64decode(image_data)\n","        frame = Image.open(io.BytesIO(image_bytes))\n","        frame = cv2.cvtColor(np.array(frame), cv2.COLOR_RGB2BGR)\n","\n","        # Process the frame\n","        class_name, confidence_score_whole = drowsy_detector.process_frame(frame)\n","\n","        # Add drowsiness details to the frame\n","        text = f\"Class: {class_name}\\nConfidence: {confidence_score_whole}%\\nDrowsy Frames: {drowsy_detector.drowsy_frame_count}\\nNon-Drowsy Frames: {drowsy_detector.non_drowsy_frame_count}\"\n","\n","        # Position the text on the right side of the frame\n","        text_x = frame.shape[1] - 300\n","        text_y = 50\n","        font = cv2.FONT_HERSHEY_SIMPLEX\n","        font_scale = 0.8\n","        font_color = (0, 255, 0)\n","        font_thickness = 2\n","\n","        # Split the text into lines\n","        lines = text.split('\\n')\n","        for i, line in enumerate(lines):\n","            y = text_y + i * 30\n","            cv2.putText(frame, line, (text_x, y), font, font_scale, font_color, font_thickness, cv2.LINE_AA)\n","\n","        # Display the result\n","        cv2_imshow(frame)\n","    except Exception as e:\n","        print(f\"Error processing frame: {e}\")\n","\n","# Register callback function\n","output.register_callback('notebook.captureFrameCallback', capture_frame_callback)\n","\n","# Start capturing\n","capture_image()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WCz5a5P_EPCr","outputId":"07b35993-1b9e-444f-e0de-b0f6f98b674f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Failed to connect to the V2V server: HTTPConnectionPool(host='127.0.0.1', port=5000): Max retries exceeded with url: /socket.io/?transport=polling&EIO=4&t=1737869118.1620016 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7c98e412bd50>: Failed to establish a new connection: [Errno 111] Connection refused'))\n"]}],"source":["\n","# Import libraries\n","import cv2\n","import numpy as np\n","from keras.models import load_model\n","from PIL import Image, ImageOps\n","from google.colab.patches import cv2_imshow\n","from google.colab import output\n","import base64\n","import io\n","from IPython.display import display, Javascript, Audio\n","import math\n","import time\n","import threading\n","import socketio\n","import queue\n","import pyttsx3\n","import os\n","\n","# Load the drowsy detection model\n","model = load_model(\"/content/keras_model.h5\", compile=False)\n","\n","# Load and process labels correctly\n","with open(\"/content/labels.txt\", \"r\") as f:\n","    class_names = [line.strip().split(' ', 1)[1] for line in f.readlines()]\n","\n","# Path to the alert sound file (converted to .mp3)\n","alert_sound_file = \"/content/alert.mp3\"\n","\n","# Initialize the V2V client\n","sio = socketio.Client()\n","\n","# Initialize the text-to-speech engine\n","engine = pyttsx3.init()\n","\n","# Create a queue for text-to-speech requests\n","speech_queue = queue.Queue()\n","\n","# Function to process text-to-speech requests\n","def speech_worker():\n","    while True:\n","        text = speech_queue.get()\n","        if text is None:\n","            break\n","        engine.say(text)\n","        engine.runAndWait()\n","        speech_queue.task_done()\n","\n","# Start the speech worker thread\n","speech_thread = threading.Thread(target=speech_worker)\n","speech_thread.daemon = True\n","speech_thread.start()\n","\n","# Function to add text to the speech queue\n","def speak(text):\n","    speech_queue.put(text)\n","\n","# Event for when the client connects to the server\n","@sio.event\n","def connect():\n","    print(\"Connected to the V2V server\")\n","    speak(\"Connected to the V2V server\")\n","\n","# Event for when the client disconnects from the server\n","@sio.event\n","def disconnect():\n","    print(\"Disconnected from the V2V server\")\n","    speak(\"Disconnected from the V2V server\")\n","\n","# Event for receiving a response from the server\n","@sio.event\n","def v2v_response(data):\n","    print(f\"Received response: {data}\")\n","    speak(f\"Received response: {data}\")\n","\n","# Connect to the V2V server\n","try:\n","    sio.connect('http://127.0.0.1:5000')\n","except Exception as e:\n","    print(f\"Failed to connect to the V2V server: {e}\")\n","    speak(\"Failed to connect to the V2V server\")\n","\n","# Class to maintain state for drowsy detection\n","class DrowsyDetector:\n","    def __init__(self):\n","        self.drowsy_frame_count = 0\n","        self.non_drowsy_frame_count = 0\n","        self.longest_drowsy_streak = 0\n","        self.longest_non_drowsy_streak = 0\n","        self.total_drowsy_frames = 0\n","        self.total_non_drowsy_frames = 0\n","        self.start_time = time.time()\n","        self.ALERT_THRESHOLD = 5  # Number of continuous drowsy frames to trigger alert sound\n","        self.V2V_THRESHOLD = 10  # Number of continuous drowsy frames to trigger V2V communication\n","\n","    def process_frame(self, frame):\n","        \"\"\"\n","        Process the frame and make a prediction.\n","        \"\"\"\n","        # Resize the frame to 224x224 pixels\n","        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","        image = Image.fromarray(image)\n","        image = ImageOps.fit(image, (224, 224), Image.Resampling.LANCZOS)\n","        image_array = np.asarray(image)\n","\n","        # Normalize the image\n","        normalized_image_array = (image_array.astype(np.float32) / 127.5) - 1\n","\n","        # Create a batch of one image\n","        data = np.expand_dims(normalized_image_array, axis=0)\n","\n","        # Perform prediction\n","        prediction = model.predict(data)\n","        index = np.argmax(prediction)\n","        class_name = class_names[index]\n","        confidence_score = prediction[0][index]\n","\n","        # Format confidence score as a whole number\n","        confidence_score_whole = int(confidence_score * 100)\n","\n","        # Check if the class is \"Drowsy\" (index 0)\n","        if index == 0:  # Directly check the index instead of class name string\n","            self.drowsy_frame_count += 1\n","            self.total_drowsy_frames += 1\n","            if self.drowsy_frame_count > self.longest_drowsy_streak:\n","                self.longest_drowsy_streak = self.drowsy_frame_count\n","            self.non_drowsy_frame_count = 0\n","            print(f\"Drowsy frame detected. Count: {self.drowsy_frame_count}\")\n","\n","            # Trigger alert sound if continuous drowsy frames exceed the alert threshold\n","            if self.drowsy_frame_count == self.ALERT_THRESHOLD:\n","                print(\"ALERT: Drowsiness detected! Playing alert sound...\")\n","                display(Audio(alert_sound_file, autoplay=True))  # Play alert sound\n","\n","            # Trigger V2V communication if continuous drowsy frames exceed the V2V threshold\n","            if self.drowsy_frame_count == self.V2V_THRESHOLD:\n","                print(\"ALERT: Drowsiness detected! Sending alert to V2V server and Traffic Police server...\")\n","                sio.emit('v2v_message', {'message': \"Driver is not responding. Need assistance!\", 'type': 'emergency'})\n","                sio.emit('traffic_police_message', {'message': \"Driver is not responding. Need assistance!\", 'type': 'emergency'})\n","                self.drowsy_frame_count = 0  # Reset the counter after alert\n","        else:\n","            self.non_drowsy_frame_count += 1\n","            self.total_non_drowsy_frames += 1\n","            if self.non_drowsy_frame_count > self.longest_non_drowsy_streak:\n","                self.longest_non_drowsy_streak = self.non_drowsy_frame_count\n","            self.drowsy_frame_count = 0\n","            print(\"Not drowsy. Resetting drowsy counter.\")\n","\n","        return class_name, confidence_score_whole\n","\n","    def get_final_stats(self):\n","        \"\"\"\n","        Get final statistics when the webcam is stopped.\n","        \"\"\"\n","        end_time = time.time()\n","        total_time = end_time - self.start_time\n","\n","        stats = {\n","            \"total_drowsy_frames\": self.total_drowsy_frames,\n","            \"total_non_drowsy_frames\": self.total_non_drowsy_frames,\n","            \"longest_drowsy_streak\": self.longest_drowsy_streak,\n","            \"longest_non_drowsy_streak\": self.longest_non_drowsy_streak,\n","            \"total_time\": total_time\n","        }\n","\n","        return stats\n","\n","# Create an instance of the DrowsyDetector class\n","drowsy_detector = DrowsyDetector()\n","\n","# Function to capture an image from the webcam via JavaScript\n","def capture_image():\n","    js = Javascript('''\n","        async function takePhoto() {\n","            const div = document.createElement('div');\n","            const video = document.createElement('video');\n","            const canvas = document.createElement('canvas');\n","            const button = document.createElement('button');\n","            button.textContent = 'Stop';\n","\n","            div.appendChild(video);\n","            div.appendChild(button);\n","            document.body.appendChild(div);\n","\n","            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n","            video.srcObject = stream;\n","            await video.play();\n","\n","            return new Promise((resolve) => {\n","                button.onclick = () => {\n","                    stream.getTracks().forEach(track => track.stop());\n","                    div.remove();\n","                    resolve(null);\n","                };\n","\n","                setInterval(async () => {\n","                    if (!video.srcObject.active) {\n","                        resolve(null);\n","                        return;\n","                    }\n","                    canvas.width = video.videoWidth;\n","                    canvas.height = video.videoHeight;\n","                    canvas.getContext('2d').drawImage(video, 0, 0);\n","                    const data = canvas.toDataURL('image/jpeg').split(',')[1];\n","                    google.colab.kernel.invokeFunction('notebook.captureFrameCallback', [data], {});\n","                }, 1000); // Capture every second\n","            });\n","        }\n","        takePhoto();\n","    ''')\n","    display(js)\n","\n","# Callback to process the captured image\n","def capture_frame_callback(image_data):\n","    if image_data is None:\n","        print(\"Stopping webcam...\")\n","        stats = drowsy_detector.get_final_stats()\n","        print(\"\\nFinal Statistics:\")\n","        print(f\"Total Drowsy Frames: {stats['total_drowsy_frames']}\")\n","        print(f\"Total Non-Drowsy Frames: {stats['total_non_drowsy_frames']}\")\n","        print(f\"Longest Drowsy Streak: {stats['longest_drowsy_streak']} frames\")\n","        print(f\"Longest Non-Drowsy Streak: {stats['longest_non_drowsy_streak']} frames\")\n","        print(f\"Total Time: {stats['total_time']:.2f} seconds\")\n","        return\n","\n","    try:\n","        # Decode the image data\n","        image_bytes = base64.b64decode(image_data)\n","        frame = Image.open(io.BytesIO(image_bytes))\n","        frame = cv2.cvtColor(np.array(frame), cv2.COLOR_RGB2BGR)\n","\n","        # Process the frame\n","        class_name, confidence_score_whole = drowsy_detector.process_frame(frame)\n","\n","        # Add drowsiness details to the frame\n","        text = f\"Class: {class_name}\\nConfidence: {confidence_score_whole}%\\nDrowsy Frames: {drowsy_detector.drowsy_frame_count}\\nNon-Drowsy Frames: {drowsy_detector.non_drowsy_frame_count}\"\n","\n","        # Position the text on the right side of the frame\n","        text_x = frame.shape[1] - 300\n","        text_y = 50\n","        font = cv2.FONT_HERSHEY_SIMPLEX\n","        font_scale = 0.8\n","        font_color = (0, 255, 0)\n","        font_thickness = 2\n","\n","        # Split the text into lines\n","        lines = text.split('\\n')\n","        for i, line in enumerate(lines):\n","            y = text_y + i * 30\n","            cv2.putText(frame, line, (text_x, y), font, font_scale, font_color, font_thickness, cv2.LINE_AA)\n","\n","        # Display the result\n","        cv2_imshow(frame)\n","    except Exception as e:\n","        print(f\"Error processing frame: {e}\")\n","\n","# Register callback function\n","output.register_callback('notebook.captureFrameCallback', capture_frame_callback)\n","\n","# Start capturing\n","capture_image()"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}